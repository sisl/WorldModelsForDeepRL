@article{0.0,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{1.0.0,
  title={Recurrent World Models Facilitate Policy Evolution},
  author={Ha, David and Schmidhuber, J{\"u}rgen},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2450--2462},
  year={2018}
}

@article{1.0.1,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@article{1.0.2,
  title={Generating sequences with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1308.0850},
  year={2013}
}

@article{1.0.3,
  title={The CMA evolution strategy: A tutorial},
  author={Hansen, Nikolaus},
  journal={arXiv preprint arXiv:1604.00772},
  year={2016}
}

@inproceedings{1.1.1,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{1.1,
  title={Incorporating Attention in World Models for Improved Dynamics Modeling},
  author={Chadha, Parth and Bablani, Deepika}
}

@article{1.2.0,
  title={How do Mixture Density RNNs Predict the Future?},
  author={Ellefsen, Kai Olav and Martin, Charles Patrick and Torresen, Jim},
  journal={arXiv preprint arXiv:1901.07859},
  year={2019}
}

@article{1.2.1,
  title={Mixture density networks},
  author={Bishop, Christopher M},
  year={1994},
  publisher={Aston University}
}

@article{1.3,
  title={Deep Neuroevolution of Recurrent and Discrete World Models},
  author={Risi, Sebastian and Stanley, Kenneth O},
  journal={arXiv preprint arXiv:1906.08857},
  year={2019}
}

@article{2.0,
  title={A Brief Survey of Deep Reinforcement Learning},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={arXiv preprint arXiv:1708.05866},
  year={2017}
}

@article{2.1.0,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{2.1.1,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{2.1.2,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06581},
  year={2015}
}

@article{2.1.3,
  title={Making Deep Q-learning methods robust to time discretization},
  author={Tallec, Corentin and Blier, L{\'e}onard and Ollivier, Yann},
  journal={arXiv preprint arXiv:1901.09732},
  year={2019}
}

@article{2.2,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{2.2.1,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@article{2.3,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{3.0,
  title={Reinforcement car racing with A3C},
  author={Jang, Se Won and Min, Jesik and Kim, Jae Hyun},
  journal={https://goo.gl/58SKBp},
  year={2017}
}

@article{3.1,
  title={Solving OpenAIâ€™s Car Racing Environment with Deep Reinforcement Learningand Dropout},
  author={van der Wal, Douwe and Intelligentie, Bachelor Opleiding Kunstmatige and Shang, Wenling},
  url={https://github.com/AMD-RIPS/RL-2018/blob/master/documents/nips/nips_2018.pdf},
  year={2018}
}

@article{3.2,
  title={Advantage Actor-Critic Methods for CarRacing},
  author={Gerber, P and Guan, J and Nunez, E and Phamdo, K and Monsoor, T and Malaya, N},
  year={2018}
}

@article{schmidhuber2015learning,
  title={On learning to think: Algorithmic information theory for novel combinations of reinforcement learning controllers and recurrent neural world models},
  author={Schmidhuber, J{\"u}rgen},
  journal={arXiv preprint arXiv:1511.09249},
  year={2015}
}

@misc{Git,
  title = {{Project Repository: WorldModelsForDeepRL}},
  author = {Manuel, Shawn},
  howpublished = {\url{https://github.com/shawnmanuel000/WorldModelsForDeepRL}},
  note = {Published: 2019-12-03}
}

@article{4.0,
  title={Deep reinforcement learning for autonomous driving},
  author={Wang, Sen and Jia, Daoyuan and Weng, Xinshuo},
  journal={arXiv preprint arXiv:1811.11329},
  year={2018}
}

@article{5.0,
  title={Asymmetric actor critic for image-based robot learning},
  author={Pinto, Lerrel and Andrychowicz, Marcin and Welinder, Peter and Zaremba, Wojciech and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1710.06542},
  year={2017}
}