Model: <class 'models.ppo.PPOAgent'>, Dir: iter1/
statemodel: <class 'utils.envs.WorldModel'>, num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE

EPS_MIN = 0.2                 	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.997             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 32					# Number of samples to train on for each train step
PPO_EPOCHS = 5					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.005				# The limit of the ratio of new action probabilities to old probabilities
DISCOUNT_RATE = 0.97			# The discount rate to use in the Bellman Equation
NUM_STEPS = 20					# The number of steps to collect experience in sequence for each GAE calculation
ADVANTAGE_DECAY = 0.99			# The discount factor for the cumulative GAE calculation

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = action_mu if not sample else dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu() + state
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			value = self.critic_local(state.to(self.device))
			return value

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=1, clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) + critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages).mean() + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss)
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.replay_buffer = PrioritizedReplayBuffer()
		self.ppo_epochs = PPO_EPOCHS
		self.ppo_batch = BATCH_SIZE

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**0.0)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False)
			next_value = self.network.get_value(next_state, grad=False)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(zip(states, actions, log_probs, targets, advantages))
			for _ in range(self.ppo_epochs):
				# self.replay_buffer.reset_priorities()
				for _ in range(update_freq):
					(state, action, log_prob, target, advantage), indices, importances = self.replay_buffer.sample(self.ppo_batch, dtype=torch.stack)
					errors = self.network.optimize(state, action, log_prob, target, advantage, importances**(1-self.eps))
					self.replay_buffer.update_priorities(indices, errors)
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0002           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.97			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.0225               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import os
import gym
import torch
import argparse
import numpy as np
from collections import deque
from models.ppo import PPOAgent
from models.rand import RandomAgent
from models.ddpg import DDPGAgent, EPS_MIN
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, WorldModel, ImgStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--iternum", type=int, default=-1, choices=[-1,0,1], help="Whether to train using World Model to load (0 or 1) or raw images (-1)")
parser.add_argument("--model", type=str, default="ddpg", choices=["ddpg", "ppo"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--runs", type=int, default=1, help="Number of episodes to train the agent")
parser.add_argument("--trial", action="store_true", help="Whether to show a trial run training on the Pendulum-v0 environment")
args = parser.parse_args()

ENV_NAME = "CarRacing-v0"

class WorldACAgent(RandomAgent):
	def __init__(self, action_size, num_envs, acagent, statemodel=WorldModel, load="", gpu=True, train=True):
		super().__init__(action_size)
		self.world_model = statemodel(action_size, num_envs, load=load, gpu=gpu)
		self.acagent = acagent(self.world_model.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state, latent = self.world_model.get_state(state)
		env_action, action = self.acagent.get_env_action(env, state, eps, sample)
		self.world_model.step(latent, env_action)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.world_model.get_state(next_state)[0]
		self.acagent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.world_model.num_envs if num_envs is None else num_envs
		self.world_model.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		self.acagent.network.save_model(dirname, name)

	def load(self, dirname="pytorch", name="best"):
		self.world_model.load_model(dirname, name)
		self.acagent.network.load_model(dirname, name)
		return self

def run(model, statemodel, runs=1, load_dir="", ports=16):
	num_envs = len(ports) if type(ports) == list else min(ports, 16)
	logger = Logger(model, load_dir, statemodel=statemodel, num_envs=num_envs)
	envs = EnvManager(ENV_NAME, ports) if type(ports) == list else EnsembleEnv(ENV_NAME, ports)
	agent = WorldACAgent(envs.action_size, num_envs, model, statemodel, load=load_dir)
	total_rewards = []
	for ep in range(runs):
		states = envs.reset()
		agent.reset(num_envs)
		total_reward = 0
		for _ in range(envs.env.spec.max_episode_steps):
			env_actions, actions, states = agent.get_env_action(envs.env, states)
			next_states, rewards, dones, _ = envs.step(env_actions, render=(ep%runs==0))
			agent.train(states, actions, next_states, rewards, dones)
			total_reward += np.mean(rewards)
			states = next_states
		rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(10)]
		test_reward = np.mean(rollouts) - np.std(rollouts)
		total_rewards.append(test_reward)
		agent.save_model(load_dir, "checkpoint")
		if total_rewards[-1] >= max(total_rewards): agent.save_model(load_dir)
		logger.log(f"Ep: {ep}, Reward: {total_reward:.4f}, Test: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.acagent.eps:.3f})")
	envs.close()

def trial(model, steps=40000, ports=16):
	env_name = "Pendulum-v0"
	envs = EnvManager(ENV_NAME, ports) if type(ports) == list else EnsembleEnv(ENV_NAME, ports)
	agent = model(envs.state_size, envs.action_size, decay=0.99)
	env = gym.make(env_name)
	state = envs.reset()
	test_rewards = []
	for s in range(steps):
		env_action, action = agent.get_env_action(env, state)
		next_state, reward, done, _ = envs.step(env_action)
		agent.train(state, action, next_state, reward, done)
		state = next_state
		if s % env.spec.max_episode_steps == 0:
			test_reward = np.mean([rollout(env, agent) for _ in range(10)])
			test_rewards.append(test_reward)
			print(f"Ep: {s//env.spec.max_episode_steps}, Rewards: {test_reward}, Avg: {np.mean(test_rewards)}")
			if test_reward > -200: break
	env.close()
	envs.close()

if __name__ == "__main__":
	dirname = "pytorch" if args.iternum < 0 else f"iter{args.iternum}/"
	state = ImgStack if args.iternum < 0 else WorldModel
	model = PPOAgent if args.model == "ppo" else DDPGAgent
	if args.trial:
		trial(model, ports=args.workerports)
	elif args.selfport is not None:
		EnvWorker(args.selfport, ENV_NAME).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, state, args.runs, dirname, args.workerports)

Ep: 0, Reward: -37.8612, Test: -20.9214 [15.86], Avg: -36.7859 (0.997)
Ep: 1, Reward: -37.5248, Test: -15.9788 [19.26], Avg: -36.0107 (0.994)
Ep: 2, Reward: -34.3803, Test: -20.7308 [17.42], Avg: -36.7233 (0.991)
Ep: 3, Reward: -30.1874, Test: -20.1590 [18.60], Avg: -37.2320 (0.988)
Ep: 4, Reward: -31.5868, Test: -27.9921 [16.30], Avg: -38.6439 (0.985)
Ep: 5, Reward: -34.2770, Test: -18.7408 [22.04], Avg: -39.0002 (0.982)
Ep: 6, Reward: -29.9299, Test: -7.0627 [25.55], Avg: -38.0877 (0.979)
Ep: 7, Reward: -29.2395, Test: -19.6933 [23.30], Avg: -38.7007 (0.976)
Ep: 8, Reward: -35.0191, Test: -100.3659 [41.18], Avg: -50.1277 (0.973)
Ep: 9, Reward: -44.1686, Test: -82.3333 [71.57], Avg: -60.5057 (0.970)
Ep: 10, Reward: -36.1173, Test: -100.4341 [41.62], Avg: -67.9188 (0.967)
Ep: 11, Reward: -38.2145, Test: -119.4244 [11.48], Avg: -73.1673 (0.965)
Ep: 12, Reward: -43.2425, Test: -124.4738 [6.16], Avg: -77.5877 (0.962)
Ep: 13, Reward: -52.6910, Test: -105.3437 [24.93], Avg: -81.3506 (0.959)
Ep: 14, Reward: -45.2827, Test: -127.1847 [7.98], Avg: -84.9383 (0.956)
Ep: 15, Reward: -45.9717, Test: -109.6375 [4.22], Avg: -86.7456 (0.953)
Ep: 16, Reward: -54.6207, Test: -111.7874 [24.64], Avg: -89.6680 (0.950)
Ep: 17, Reward: -58.6948, Test: -101.4505 [18.76], Avg: -91.3649 (0.947)
Ep: 18, Reward: -57.7535, Test: -76.0246 [32.12], Avg: -92.2478 (0.945)
Ep: 19, Reward: -52.0242, Test: -91.1008 [43.91], Avg: -94.3860 (0.942)
Ep: 20, Reward: -47.0111, Test: -104.0259 [19.55], Avg: -95.7760 (0.939)
Ep: 21, Reward: -53.7313, Test: -109.6839 [12.76], Avg: -96.9880 (0.936)
Ep: 22, Reward: -61.2283, Test: -104.5678 [32.06], Avg: -98.7113 (0.933)
Ep: 23, Reward: -59.5721, Test: -100.3533 [32.17], Avg: -100.1201 (0.930)
Ep: 24, Reward: -58.1146, Test: -102.3928 [28.07], Avg: -101.3339 (0.928)
Ep: 25, Reward: -59.4536, Test: -106.8642 [32.11], Avg: -102.7816 (0.925)
Ep: 26, Reward: -56.4943, Test: -71.5959 [6.78], Avg: -101.8776 (0.922)
Ep: 27, Reward: -54.4739, Test: -49.3203 [28.50], Avg: -101.0185 (0.919)
Ep: 28, Reward: -47.2732, Test: -61.3062 [15.98], Avg: -100.2001 (0.917)
Ep: 29, Reward: -51.4439, Test: -66.7016 [16.84], Avg: -99.6449 (0.914)
Ep: 30, Reward: -68.3703, Test: -68.2285 [10.91], Avg: -98.9834 (0.911)
Ep: 31, Reward: -51.1321, Test: -72.2581 [7.80], Avg: -98.3921 (0.908)
Ep: 32, Reward: -57.4286, Test: -71.4470 [8.34], Avg: -97.8284 (0.906)
Ep: 33, Reward: -32.8159, Test: -71.3817 [7.82], Avg: -97.2806 (0.903)
Ep: 34, Reward: -36.7652, Test: -64.0280 [10.80], Avg: -96.6392 (0.900)
Ep: 35, Reward: -56.0413, Test: -58.8038 [9.17], Avg: -95.8430 (0.897)
Ep: 36, Reward: -40.4943, Test: -58.7500 [16.55], Avg: -95.2878 (0.895)
Ep: 37, Reward: -9.1258, Test: -58.0909 [18.00], Avg: -94.7827 (0.892)
Ep: 38, Reward: 5.2307, Test: -50.9520 [15.15], Avg: -94.0474 (0.889)
Ep: 39, Reward: 27.0382, Test: -8.9727 [40.93], Avg: -92.9437 (0.887)
Ep: 40, Reward: 97.8463, Test: 2.4662 [48.19], Avg: -91.7921 (0.884)
Ep: 41, Reward: 141.5002, Test: -0.6626 [49.75], Avg: -90.8068 (0.881)
Ep: 42, Reward: 170.0928, Test: 27.4297 [41.66], Avg: -89.0260 (0.879)
Ep: 43, Reward: 180.4499, Test: -8.1879 [33.55], Avg: -87.9512 (0.876)
Ep: 44, Reward: 97.7777, Test: -24.0020 [35.31], Avg: -87.3147 (0.874)
Ep: 45, Reward: 125.5854, Test: -6.9924 [30.89], Avg: -86.2402 (0.871)
Ep: 46, Reward: 203.7906, Test: -1.2072 [72.41], Avg: -85.9716 (0.868)
Ep: 47, Reward: 137.2925, Test: 0.8258 [45.87], Avg: -85.1189 (0.866)
Ep: 48, Reward: 145.5150, Test: 15.0985 [68.93], Avg: -84.4803 (0.863)
Ep: 49, Reward: 213.1714, Test: -7.6549 [34.61], Avg: -83.6360 (0.861)
Ep: 50, Reward: 140.4071, Test: 4.1920 [61.88], Avg: -83.1271 (0.858)
Ep: 51, Reward: 331.1286, Test: 153.5675 [192.98], Avg: -82.2864 (0.855)
Ep: 52, Reward: 251.4529, Test: 97.1666 [152.15], Avg: -81.7713 (0.853)
Ep: 53, Reward: 246.1621, Test: 131.9038 [140.27], Avg: -80.4120 (0.850)
Ep: 54, Reward: 233.5863, Test: 49.5330 [68.28], Avg: -79.2909 (0.848)
Ep: 55, Reward: 159.7970, Test: 124.6144 [173.53], Avg: -78.7485 (0.845)
Ep: 56, Reward: 114.3706, Test: 210.6387 [147.53], Avg: -76.2598 (0.843)
Ep: 57, Reward: 175.5641, Test: -2.5452 [36.09], Avg: -75.6112 (0.840)
Ep: 58, Reward: -14.6878, Test: -3.4735 [83.57], Avg: -75.8049 (0.838)
Ep: 59, Reward: -17.6433, Test: -24.5666 [21.52], Avg: -75.3095 (0.835)
Ep: 60, Reward: -22.6843, Test: -39.7983 [20.67], Avg: -75.0662 (0.833)
Ep: 61, Reward: -31.9737, Test: -49.1165 [9.18], Avg: -74.7958 (0.830)
Ep: 62, Reward: -30.8193, Test: -48.6825 [18.18], Avg: -74.6698 (0.828)
Ep: 63, Reward: -40.8963, Test: -43.3254 [14.43], Avg: -74.4056 (0.825)
Ep: 64, Reward: -29.8982, Test: -46.3218 [14.18], Avg: -74.1916 (0.823)
Ep: 65, Reward: -32.4121, Test: -49.3713 [10.00], Avg: -73.9670 (0.820)
Ep: 66, Reward: -37.5183, Test: -37.3775 [16.53], Avg: -73.6677 (0.818)
Ep: 67, Reward: -38.1927, Test: -45.4059 [16.64], Avg: -73.4968 (0.815)
Ep: 68, Reward: -35.0542, Test: -40.4155 [16.91], Avg: -73.2624 (0.813)
Ep: 69, Reward: -36.5345, Test: -12.5070 [61.18], Avg: -73.2685 (0.810)
Ep: 70, Reward: -11.9053, Test: -27.9715 [42.11], Avg: -73.2236 (0.808)
Ep: 71, Reward: -33.4905, Test: -44.2654 [8.12], Avg: -72.9342 (0.805)
Ep: 72, Reward: -43.7500, Test: -40.0117 [19.50], Avg: -72.7503 (0.803)
Ep: 73, Reward: -39.8699, Test: -48.8957 [10.32], Avg: -72.5674 (0.801)
Ep: 74, Reward: -50.7490, Test: -39.5760 [7.98], Avg: -72.2339 (0.798)
Ep: 75, Reward: -44.5037, Test: -44.6385 [14.56], Avg: -72.0624 (0.796)
Ep: 76, Reward: -40.4844, Test: -50.3505 [12.98], Avg: -71.9489 (0.793)
Ep: 77, Reward: -37.6798, Test: -39.6835 [41.60], Avg: -72.0686 (0.791)
Ep: 78, Reward: -40.9650, Test: -50.1952 [10.94], Avg: -71.9302 (0.789)
Ep: 79, Reward: -23.0246, Test: -34.8027 [33.48], Avg: -71.8847 (0.786)
Ep: 80, Reward: -35.4144, Test: -46.4531 [14.07], Avg: -71.7444 (0.784)
Ep: 81, Reward: -37.0222, Test: -41.6327 [12.00], Avg: -71.5236 (0.782)
Ep: 82, Reward: -29.9163, Test: -36.4914 [26.41], Avg: -71.4197 (0.779)
Ep: 83, Reward: -47.7756, Test: -46.3162 [22.44], Avg: -71.3880 (0.777)
Ep: 84, Reward: -40.8931, Test: -40.2979 [18.73], Avg: -71.2427 (0.775)
Ep: 85, Reward: -44.5988, Test: -42.4720 [18.58], Avg: -71.1241 (0.772)
Ep: 86, Reward: -38.8984, Test: -42.1625 [19.58], Avg: -71.0163 (0.770)
Ep: 87, Reward: -23.9806, Test: -43.1696 [13.01], Avg: -70.8477 (0.768)
Ep: 88, Reward: -22.5212, Test: -35.4128 [12.19], Avg: -70.5865 (0.765)
Ep: 89, Reward: -21.8637, Test: -2.3013 [73.28], Avg: -70.6420 (0.763)
Ep: 90, Reward: -16.8488, Test: -41.8456 [17.08], Avg: -70.5133 (0.761)
Ep: 91, Reward: -37.7420, Test: -18.2592 [52.33], Avg: -70.5141 (0.758)
Ep: 92, Reward: -21.2047, Test: -26.5495 [60.64], Avg: -70.6934 (0.756)
Ep: 93, Reward: -24.9296, Test: 22.6417 [114.60], Avg: -70.9196 (0.754)
Ep: 94, Reward: 42.9268, Test: -16.9108 [73.07], Avg: -71.1203 (0.752)
Ep: 95, Reward: 1.9579, Test: -2.1911 [57.86], Avg: -71.0051 (0.749)
Ep: 96, Reward: 46.7959, Test: 40.3704 [96.61], Avg: -70.8528 (0.747)
Ep: 97, Reward: 73.7477, Test: 152.8673 [103.65], Avg: -69.6276 (0.745)
Ep: 98, Reward: 110.8268, Test: 105.4386 [130.64], Avg: -69.1789 (0.743)
Ep: 99, Reward: 91.3522, Test: 143.1686 [113.85], Avg: -68.1939 (0.740)
Ep: 100, Reward: 78.5842, Test: 77.1821 [129.17], Avg: -68.0334 (0.738)
Ep: 101, Reward: 50.1233, Test: 29.8759 [120.25], Avg: -68.2525 (0.736)
Ep: 102, Reward: 45.6230, Test: 17.7599 [72.02], Avg: -68.1166 (0.734)
Ep: 103, Reward: 31.4379, Test: 43.0575 [100.47], Avg: -68.0136 (0.732)
Ep: 104, Reward: 76.9582, Test: 21.0990 [124.35], Avg: -68.3493 (0.729)
Ep: 105, Reward: 67.7860, Test: 43.8790 [94.87], Avg: -68.1855 (0.727)
Ep: 106, Reward: 24.0879, Test: 57.6757 [104.91], Avg: -67.9897 (0.725)
Ep: 107, Reward: 33.3092, Test: 137.8510 [197.67], Avg: -67.9140 (0.723)
Ep: 108, Reward: 44.3482, Test: 67.1980 [123.71], Avg: -67.8094 (0.721)
Ep: 109, Reward: 102.6612, Test: 34.5753 [81.56], Avg: -67.6201 (0.719)
Ep: 110, Reward: 71.6613, Test: -9.6357 [13.39], Avg: -67.2184 (0.716)
Ep: 111, Reward: 151.9333, Test: 143.0866 [107.86], Avg: -66.3037 (0.714)
Ep: 112, Reward: 117.9479, Test: 197.9108 [146.71], Avg: -65.2638 (0.712)
Ep: 113, Reward: 176.8615, Test: 141.1225 [135.71], Avg: -64.6438 (0.710)
Ep: 114, Reward: 170.2277, Test: 123.3107 [166.50], Avg: -64.4573 (0.708)
Ep: 115, Reward: 120.7688, Test: 19.1296 [30.95], Avg: -64.0035 (0.706)
Ep: 116, Reward: 41.5696, Test: 17.8655 [70.19], Avg: -63.9037 (0.704)
Ep: 117, Reward: 12.1967, Test: 16.9004 [61.47], Avg: -63.7399 (0.702)
Ep: 118, Reward: 30.1321, Test: 19.3841 [65.46], Avg: -63.5914 (0.699)
Ep: 119, Reward: -15.4514, Test: -10.1884 [42.19], Avg: -63.4980 (0.697)
Ep: 120, Reward: 10.6175, Test: -21.9276 [49.64], Avg: -63.5647 (0.695)
Ep: 121, Reward: -16.3954, Test: -21.0357 [19.06], Avg: -63.3723 (0.693)
Ep: 122, Reward: -16.3305, Test: 15.5491 [71.66], Avg: -63.3133 (0.691)
Ep: 123, Reward: -13.3300, Test: -22.9296 [31.12], Avg: -63.2385 (0.689)
Ep: 124, Reward: -7.4893, Test: 14.4083 [25.99], Avg: -62.8253 (0.687)
Ep: 125, Reward: -17.1473, Test: -6.9681 [62.03], Avg: -62.8743 (0.685)
Ep: 126, Reward: -11.2034, Test: 5.9623 [27.89], Avg: -62.5519 (0.683)
Ep: 127, Reward: -13.3265, Test: -19.6220 [25.01], Avg: -62.4118 (0.681)
Ep: 128, Reward: 16.6434, Test: 56.1341 [86.14], Avg: -62.1606 (0.679)
Ep: 129, Reward: 7.9882, Test: 38.3275 [85.15], Avg: -62.0426 (0.677)
Ep: 130, Reward: 53.5011, Test: 71.8787 [79.88], Avg: -61.6301 (0.675)
Ep: 131, Reward: 84.3614, Test: 241.1766 [187.83], Avg: -60.7590 (0.673)
Ep: 132, Reward: 172.2789, Test: 223.0267 [110.12], Avg: -59.4532 (0.671)
Ep: 133, Reward: 201.6066, Test: 226.6278 [90.62], Avg: -57.9945 (0.669)
Ep: 134, Reward: 201.0107, Test: 219.4472 [78.46], Avg: -56.5206 (0.667)
Ep: 135, Reward: 203.4252, Test: 269.5726 [146.77], Avg: -55.2021 (0.665)
Ep: 136, Reward: 205.2531, Test: 316.1855 [120.02], Avg: -53.3673 (0.663)
Ep: 137, Reward: 189.8880, Test: 162.0267 [119.39], Avg: -52.6716 (0.661)
Ep: 138, Reward: 215.2521, Test: 225.8913 [247.48], Avg: -52.4480 (0.659)
Ep: 139, Reward: 174.0220, Test: 249.3058 [110.35], Avg: -51.0808 (0.657)
Ep: 140, Reward: 268.6571, Test: 296.5035 [129.14], Avg: -49.5316 (0.655)
Ep: 141, Reward: 241.4805, Test: 161.1921 [88.64], Avg: -48.6718 (0.653)
Ep: 142, Reward: 212.9996, Test: 138.6868 [112.50], Avg: -48.1484 (0.651)
Ep: 143, Reward: 213.6836, Test: 53.7480 [86.03], Avg: -48.0382 (0.649)
Ep: 144, Reward: 72.5661, Test: 7.4500 [71.22], Avg: -48.1467 (0.647)
Ep: 145, Reward: 75.6366, Test: 86.3144 [65.23], Avg: -47.6725 (0.645)
Ep: 146, Reward: 110.2748, Test: 119.8864 [129.97], Avg: -47.4168 (0.643)
Ep: 147, Reward: 137.1725, Test: 172.5531 [95.39], Avg: -46.5751 (0.641)
Ep: 148, Reward: 185.2678, Test: 147.0396 [97.62], Avg: -45.9308 (0.639)
Ep: 149, Reward: 203.3966, Test: 171.2147 [150.67], Avg: -45.4876 (0.637)
Ep: 150, Reward: 221.2862, Test: 237.2192 [211.20], Avg: -45.0141 (0.635)
Ep: 151, Reward: 196.2325, Test: -2.5475 [61.22], Avg: -45.1375 (0.633)
Ep: 152, Reward: 23.6711, Test: -11.8389 [39.30], Avg: -45.1767 (0.631)
Ep: 153, Reward: 15.7706, Test: 5.9111 [72.40], Avg: -45.3151 (0.630)
Ep: 154, Reward: 63.9718, Test: 83.1922 [96.50], Avg: -45.1086 (0.628)
Ep: 155, Reward: 47.2218, Test: 113.1965 [118.83], Avg: -44.8556 (0.626)
Ep: 156, Reward: 130.1844, Test: 43.8392 [71.46], Avg: -44.7458 (0.624)
Ep: 157, Reward: 62.7301, Test: 24.7532 [48.99], Avg: -44.6160 (0.622)
Ep: 158, Reward: 103.8008, Test: 151.6133 [136.74], Avg: -44.2418 (0.620)
Ep: 159, Reward: 354.4373, Test: 228.8484 [201.41], Avg: -43.7938 (0.618)
Ep: 160, Reward: 232.9252, Test: 184.5817 [160.87], Avg: -43.3746 (0.616)
Ep: 161, Reward: 210.7451, Test: 118.2286 [122.76], Avg: -43.1348 (0.615)
Ep: 162, Reward: 140.3197, Test: 226.8392 [258.59], Avg: -43.0650 (0.613)
Ep: 163, Reward: 452.9718, Test: 189.2954 [190.06], Avg: -42.8071 (0.611)
Ep: 164, Reward: 324.1536, Test: 176.5831 [244.16], Avg: -42.9572 (0.609)
Ep: 165, Reward: 167.0409, Test: 87.5704 [154.81], Avg: -43.1035 (0.605)
Ep: 166, Reward: 259.0694, Test: 430.1544 [247.78], Avg: -41.7533 (0.604)
Ep: 167, Reward: 541.2968, Test: 409.7492 [327.32], Avg: -41.0141 (0.602)
Ep: 168, Reward: 414.2096, Test: 442.6783 [244.14], Avg: -39.5967 (0.600)
Ep: 169, Reward: 418.2569, Test: 490.2810 [243.48], Avg: -37.9120 (0.598)
Ep: 170, Reward: 392.5399, Test: 339.2926 [271.60], Avg: -37.2945 (0.596)
Ep: 171, Reward: 445.8537, Test: 377.3402 [257.86], Avg: -36.3830 (0.595)
Ep: 172, Reward: 489.1864, Test: 169.1095 [146.96], Avg: -36.0447 (0.593)
Ep: 173, Reward: 287.4502, Test: 322.5307 [201.15], Avg: -35.1399 (0.591)
Ep: 174, Reward: 283.6990, Test: 317.9461 [223.73], Avg: -34.4008 (0.589)
Ep: 175, Reward: 355.9500, Test: 437.4560 [317.43], Avg: -33.5233 (0.588)
Ep: 176, Reward: 383.3541, Test: 210.8435 [217.98], Avg: -33.3742 (0.586)
Ep: 177, Reward: 246.4316, Test: 224.6570 [161.06], Avg: -32.8294 (0.584)
Ep: 178, Reward: 213.8485, Test: 232.7953 [185.20], Avg: -32.3801 (0.582)
Ep: 179, Reward: 178.4540, Test: 1.1222 [37.34], Avg: -32.4014 (0.581)
Ep: 180, Reward: 137.2603, Test: 64.8890 [142.15], Avg: -32.6492 (0.577)
Ep: 181, Reward: 79.8133, Test: -36.0083 [30.25], Avg: -32.8339 (0.575)
Ep: 182, Reward: -13.5408, Test: -27.9551 [43.63], Avg: -33.0457 (0.574)
Ep: 183, Reward: -22.6764, Test: -17.0775 [40.48], Avg: -33.1789 (0.572)
Ep: 184, Reward: -24.5765, Test: 27.2437 [98.60], Avg: -33.3852 (0.570)
Ep: 185, Reward: 69.9622, Test: 44.1997 [76.90], Avg: -33.3816 (0.568)
Ep: 186, Reward: 9.6807, Test: 11.1306 [58.42], Avg: -33.4560 (0.567)
Ep: 187, Reward: -43.4222, Test: -58.6084 [13.25], Avg: -33.6602 (0.565)
Ep: 188, Reward: -29.9564, Test: -41.1877 [36.44], Avg: -33.8929 (0.563)
Ep: 189, Reward: -19.2640, Test: -48.9137 [24.06], Avg: -34.0985 (0.562)
Ep: 190, Reward: -32.4936, Test: 67.6450 [137.38], Avg: -34.2851 (0.560)
Ep: 191, Reward: 64.5266, Test: 27.9024 [117.11], Avg: -34.5712 (0.558)
Ep: 192, Reward: 41.2275, Test: -30.3137 [76.39], Avg: -34.9449 (0.557)
Ep: 193, Reward: -41.5004, Test: -39.1028 [43.96], Avg: -35.1929 (0.555)
Ep: 194, Reward: -45.1832, Test: -52.0999 [12.93], Avg: -35.3460 (0.553)
Ep: 195, Reward: -22.4391, Test: -29.7489 [47.66], Avg: -35.5606 (0.552)
Ep: 196, Reward: -9.7897, Test: -6.2069 [53.76], Avg: -35.6845 (0.550)
Ep: 197, Reward: -29.0103, Test: -28.9110 [40.79], Avg: -35.8563 (0.548)
Ep: 198, Reward: 6.7872, Test: -2.5035 [58.29], Avg: -35.9816 (0.547)
Ep: 199, Reward: -28.6960, Test: -30.9985 [37.51], Avg: -36.1442 (0.545)
Ep: 200, Reward: 11.5171, Test: -2.2580 [66.43], Avg: -36.3062 (0.543)
Ep: 201, Reward: -29.6449, Test: -10.5360 [74.26], Avg: -36.5462 (0.542)
Ep: 202, Reward: 33.5000, Test: 5.5202 [58.24], Avg: -36.6259 (0.540)
Ep: 203, Reward: 30.1636, Test: 6.4486 [60.45], Avg: -36.7110 (0.539)
Ep: 204, Reward: -8.8503, Test: 34.3655 [91.01], Avg: -36.8082 (0.537)
Ep: 205, Reward: 6.9339, Test: 12.9129 [62.70], Avg: -36.8712 (0.535)
Ep: 206, Reward: -26.6230, Test: 261.0610 [227.86], Avg: -36.5327 (0.534)
Ep: 207, Reward: 153.8916, Test: 63.5485 [105.79], Avg: -36.5602 (0.532)
Ep: 208, Reward: 121.0705, Test: 171.9154 [244.70], Avg: -36.7335 (0.530)
Ep: 209, Reward: 293.5776, Test: 221.0446 [194.17], Avg: -36.4306 (0.529)
Ep: 210, Reward: 284.7410, Test: 287.5565 [183.91], Avg: -35.7667 (0.527)
Ep: 211, Reward: 232.2783, Test: 99.8759 [137.34], Avg: -35.7747 (0.526)
Ep: 212, Reward: 158.8235, Test: 148.0800 [141.81], Avg: -35.5773 (0.524)
Ep: 213, Reward: 191.0105, Test: 237.0130 [126.27], Avg: -34.8936 (0.523)
Ep: 214, Reward: 173.1147, Test: 609.4065 [178.61], Avg: -32.7276 (0.521)
Ep: 215, Reward: 460.8960, Test: 462.2918 [252.57], Avg: -31.6051 (0.519)
Ep: 216, Reward: 489.1357, Test: 623.3922 [244.76], Avg: -29.7146 (0.518)
Ep: 217, Reward: 609.6781, Test: 539.9761 [253.69], Avg: -28.2650 (0.516)
Ep: 218, Reward: 601.5024, Test: 680.0279 [87.80], Avg: -25.4318 (0.515)
Ep: 219, Reward: 439.2370, Test: 466.5472 [194.86], Avg: -24.0812 (0.513)
Ep: 220, Reward: 524.0791, Test: 571.2244 [133.18], Avg: -21.9902 (0.512)
Ep: 221, Reward: 616.1581, Test: 677.7838 [189.23], Avg: -19.6904 (0.510)
Ep: 222, Reward: 636.2336, Test: 456.7442 [245.39], Avg: -18.6543 (0.509)
Ep: 223, Reward: 389.6839, Test: 347.4315 [228.76], Avg: -18.0413 (0.507)
Ep: 224, Reward: 363.1725, Test: 371.8920 [198.78], Avg: -17.1917 (0.506)
Ep: 225, Reward: 311.9069, Test: 305.0477 [177.51], Avg: -16.5513 (0.504)
Ep: 226, Reward: 412.5986, Test: 359.8524 [165.42], Avg: -15.6219 (0.503)
Ep: 227, Reward: 424.4360, Test: 515.5950 [164.59], Avg: -14.0139 (0.501)
Ep: 228, Reward: 443.6942, Test: 375.4915 [181.71], Avg: -13.1065 (0.500)
Ep: 229, Reward: 381.3109, Test: 335.6539 [219.33], Avg: -12.5437 (0.498)
Ep: 230, Reward: 427.6258, Test: 392.5299 [305.93], Avg: -12.1145 (0.497)
Ep: 231, Reward: 444.1045, Test: 300.6340 [232.49], Avg: -11.7686 (0.494)
Ep: 232, Reward: 590.7808, Test: 499.3483 [256.08], Avg: -10.6740 (0.492)
Ep: 233, Reward: 510.4386, Test: 423.4626 [315.88], Avg: -10.1686 (0.491)
Ep: 234, Reward: 396.6281, Test: 246.1016 [142.44], Avg: -9.6843 (0.489)
Ep: 235, Reward: 457.0936, Test: 253.9875 [258.68], Avg: -9.6631 (0.488)
Ep: 236, Reward: 130.3168, Test: -83.3935 [32.82], Avg: -10.1127 (0.485)
Ep: 237, Reward: -112.4447, Test: -74.3347 [5.71], Avg: -10.4065 (0.483)
Ep: 238, Reward: -85.0526, Test: -69.8828 [9.08], Avg: -10.6934 (0.482)
Ep: 239, Reward: -69.1739, Test: -77.4084 [2.95], Avg: -10.9836 (0.480)
Ep: 240, Reward: -79.7079, Test: -76.3122 [3.31], Avg: -11.2685 (0.479)
Ep: 241, Reward: -74.6094, Test: -72.4319 [9.38], Avg: -11.5599 (0.478)
Ep: 242, Reward: -77.8805, Test: -66.7316 [13.51], Avg: -11.8426 (0.476)
Ep: 243, Reward: -64.8601, Test: -68.8013 [12.10], Avg: -12.1256 (0.475)
Ep: 244, Reward: -78.4677, Test: -75.5988 [18.51], Avg: -12.4603 (0.473)
Ep: 245, Reward: -81.6744, Test: -74.3825 [17.95], Avg: -12.7850 (0.470)
Ep: 246, Reward: -70.7495, Test: -77.8002 [38.01], Avg: -13.2021 (0.469)
Ep: 247, Reward: -96.2589, Test: -48.0809 [90.04], Avg: -13.7058 (0.466)
Ep: 248, Reward: 10.9916, Test: 6.8783 [105.94], Avg: -14.0486 (0.465)
Ep: 249, Reward: 60.3776, Test: 115.0158 [197.08], Avg: -14.3206 (0.462)
Ep: 250, Reward: 166.8656, Test: 112.5459 [260.77], Avg: -14.8541 (0.461)
Ep: 251, Reward: 259.6582, Test: 208.2913 [178.89], Avg: -14.6785 (0.459)
Ep: 252, Reward: 240.0874, Test: 122.9237 [260.14], Avg: -15.1629 (0.458)
Ep: 253, Reward: 107.6869, Test: 69.0879 [180.78], Avg: -15.5429 (0.455)
Ep: 254, Reward: 189.1645, Test: 21.7413 [114.79], Avg: -15.8468 (0.454)
Ep: 255, Reward: 106.2394, Test: 121.7643 [183.73], Avg: -16.0270 (0.452)
Ep: 256, Reward: 313.4636, Test: 194.7149 [215.51], Avg: -16.0456 (0.451)
Ep: 257, Reward: 309.9351, Test: 2.3057 [103.05], Avg: -16.3739 (0.450)
Ep: 258, Reward: 189.8881, Test: 5.8097 [129.33], Avg: -16.7876 (0.448)
Ep: 259, Reward: 155.6769, Test: 153.5263 [245.25], Avg: -17.0758 (0.447)
Ep: 260, Reward: 99.5140, Test: -71.1570 [21.40], Avg: -17.3650 (0.446)
Ep: 261, Reward: 68.1594, Test: 112.0968 [170.49], Avg: -17.5216 (0.444)
Ep: 262, Reward: 176.5759, Test: 197.2120 [176.56], Avg: -17.3764 (0.443)
Ep: 263, Reward: 285.3557, Test: 136.9977 [221.50], Avg: -17.6307 (0.442)
Ep: 264, Reward: 320.6882, Test: 201.8951 [211.14], Avg: -17.5990 (0.440)
Ep: 265, Reward: 181.2999, Test: 308.5520 [307.95], Avg: -17.5306 (0.439)
Ep: 266, Reward: 237.1053, Test: 34.3728 [92.60], Avg: -17.6830 (0.438)
Ep: 267, Reward: 189.8110, Test: 282.5622 [196.94], Avg: -17.2976 (0.436)
Ep: 268, Reward: 253.7089, Test: 283.5505 [185.01], Avg: -16.8669 (0.435)
Ep: 269, Reward: 386.9609, Test: 307.9672 [231.21], Avg: -16.5202 (0.434)
Ep: 270, Reward: 413.6258, Test: 117.3785 [154.26], Avg: -16.5953 (0.432)
Ep: 271, Reward: 307.9597, Test: 311.5915 [255.23], Avg: -16.3271 (0.431)
Ep: 272, Reward: 329.1444, Test: 305.3741 [231.49], Avg: -15.9967 (0.430)
Ep: 273, Reward: 410.6723, Test: 264.1051 [207.21], Avg: -15.7306 (0.429)
Ep: 274, Reward: 293.8371, Test: 196.9526 [238.87], Avg: -15.8259 (0.427)
Ep: 275, Reward: 271.4306, Test: 190.2560 [184.76], Avg: -15.7486 (0.426)
Ep: 276, Reward: 315.8291, Test: 321.8845 [249.11], Avg: -15.4290 (0.425)
Ep: 277, Reward: 358.4997, Test: 313.1124 [174.19], Avg: -14.8738 (0.423)
Ep: 278, Reward: 389.8089, Test: 396.5955 [261.12], Avg: -14.3349 (0.422)
Ep: 279, Reward: 404.2581, Test: 248.0821 [181.58], Avg: -14.0462 (0.421)
Ep: 280, Reward: 348.3828, Test: 277.1140 [245.65], Avg: -13.8843 (0.420)
Ep: 281, Reward: 280.5386, Test: 219.2517 [164.13], Avg: -13.6396 (0.418)
Ep: 282, Reward: 354.3335, Test: 263.2092 [286.16], Avg: -13.6725 (0.417)
Ep: 283, Reward: 448.9043, Test: 412.7002 [265.00], Avg: -13.1043 (0.416)
Ep: 284, Reward: 416.0453, Test: 282.1056 [210.63], Avg: -12.8075 (0.415)
Ep: 285, Reward: 354.8973, Test: 260.0251 [226.48], Avg: -12.6454 (0.413)
Ep: 286, Reward: 288.3535, Test: 292.0807 [211.99], Avg: -12.3223 (0.412)
Ep: 287, Reward: 193.8922, Test: 126.9062 [242.01], Avg: -12.6792 (0.411)
Ep: 288, Reward: 256.8303, Test: 320.1335 [199.72], Avg: -12.2187 (0.410)
Ep: 289, Reward: 331.2242, Test: 187.2397 [226.13], Avg: -12.3107 (0.407)
Ep: 290, Reward: 164.0428, Test: -115.7133 [26.47], Avg: -12.7570 (0.405)
Ep: 291, Reward: -248.7546, Test: -100.8047 [17.89], Avg: -13.1198 (0.404)
Ep: 292, Reward: -224.3965, Test: -97.1918 [30.29], Avg: -13.5101 (0.401)
Ep: 293, Reward: -231.0132, Test: -119.9717 [14.53], Avg: -13.9216 (0.396)
Ep: 294, Reward: -251.6500, Test: -123.8361 [19.88], Avg: -14.3616 (0.394)
Ep: 295, Reward: -194.1771, Test: -115.9734 [17.81], Avg: -14.7650 (0.390)
Ep: 296, Reward: -222.7415, Test: -105.8634 [22.45], Avg: -15.1473 (0.388)
Ep: 297, Reward: -245.2979, Test: -107.8266 [15.40], Avg: -15.5100 (0.385)
Ep: 298, Reward: -159.7049, Test: -41.3064 [82.11], Avg: -15.8709 (0.382)
Ep: 299, Reward: -79.2495, Test: -81.9849 [23.92], Avg: -16.1710 (0.381)
Ep: 300, Reward: -205.8564, Test: -102.5800 [27.65], Avg: -16.5500 (0.377)
Ep: 301, Reward: -220.0099, Test: -98.0566 [6.08], Avg: -16.8400 (0.372)
Ep: 302, Reward: -231.7546, Test: -106.7183 [13.38], Avg: -17.1807 (0.369)
Ep: 303, Reward: -203.5627, Test: -102.3313 [14.38], Avg: -17.5081 (0.367)
Ep: 304, Reward: -286.9732, Test: -103.6057 [10.26], Avg: -17.8241 (0.364)
Ep: 305, Reward: -218.3440, Test: -97.2265 [15.56], Avg: -18.1344 (0.363)
Ep: 306, Reward: -202.6639, Test: -103.8493 [12.09], Avg: -18.4530 (0.360)
Ep: 307, Reward: -245.3410, Test: -95.2820 [18.67], Avg: -18.7631 (0.358)
Ep: 308, Reward: -112.6079, Test: -82.0121 [38.86], Avg: -19.0935 (0.357)
Ep: 309, Reward: -65.4248, Test: -62.7329 [13.35], Avg: -19.2774 (0.356)
Ep: 310, Reward: -70.0841, Test: -66.9882 [12.74], Avg: -19.4718 (0.355)
Ep: 311, Reward: -63.3248, Test: -54.5752 [24.18], Avg: -19.6618 (0.354)
Ep: 312, Reward: -49.4635, Test: -43.7039 [22.04], Avg: -19.8090 (0.353)
Ep: 313, Reward: -63.8435, Test: -64.6552 [20.21], Avg: -20.0162 (0.351)
Ep: 314, Reward: -44.1071, Test: -55.1127 [21.58], Avg: -20.1961 (0.350)
Ep: 315, Reward: -52.4222, Test: -55.0639 [17.18], Avg: -20.3608 (0.349)
Ep: 316, Reward: -49.5072, Test: -52.0840 [17.45], Avg: -20.5159 (0.348)
Ep: 317, Reward: -44.0103, Test: -59.7972 [18.98], Avg: -20.6992 (0.347)
Ep: 318, Reward: -55.1198, Test: -42.9431 [33.57], Avg: -20.8741 (0.346)
Ep: 319, Reward: -53.5757, Test: -56.2488 [17.57], Avg: -21.0396 (0.345)
Ep: 320, Reward: -52.0650, Test: -58.0493 [19.55], Avg: -21.2157 (0.344)
Ep: 321, Reward: -46.7678, Test: -62.5612 [11.89], Avg: -21.3811 (0.343)
Ep: 322, Reward: -62.0827, Test: -47.3375 [25.30], Avg: -21.5398 (0.342)
Ep: 323, Reward: -62.4316, Test: -82.8852 [33.44], Avg: -21.8323 (0.341)
Ep: 324, Reward: -110.4427, Test: -73.3012 [28.24], Avg: -22.0776 (0.340)
Ep: 325, Reward: -91.6187, Test: -85.8118 [16.74], Avg: -22.3244 (0.338)
Ep: 326, Reward: -93.5312, Test: -88.1202 [27.65], Avg: -22.6102 (0.337)
Ep: 327, Reward: -111.0010, Test: -82.7491 [29.53], Avg: -22.8836 (0.336)
Ep: 328, Reward: -65.3093, Test: -69.6577 [14.03], Avg: -23.0684 (0.335)
Ep: 329, Reward: -70.8030, Test: -79.2772 [9.72], Avg: -23.2682 (0.334)
Ep: 330, Reward: -69.3825, Test: -77.7570 [18.09], Avg: -23.4875 (0.333)
Ep: 331, Reward: -77.8048, Test: -79.1174 [33.00], Avg: -23.7544 (0.332)
Ep: 332, Reward: -68.9802, Test: -72.1218 [33.88], Avg: -24.0014 (0.331)
Ep: 333, Reward: -67.9868, Test: -65.6802 [20.75], Avg: -24.1883 (0.330)
Ep: 334, Reward: -79.4486, Test: -68.1800 [21.05], Avg: -24.3825 (0.329)
Ep: 335, Reward: -93.5872, Test: -75.8710 [7.82], Avg: -24.5590 (0.328)
Ep: 336, Reward: -72.4965, Test: -77.0988 [13.13], Avg: -24.7539 (0.327)
Ep: 337, Reward: -73.6525, Test: -74.6344 [7.02], Avg: -24.9222 (0.326)
Ep: 338, Reward: -82.7524, Test: -74.4586 [9.88], Avg: -25.0975 (0.325)
Ep: 339, Reward: -79.5564, Test: -77.3297 [5.24], Avg: -25.2665 (0.324)
Ep: 340, Reward: -77.2517, Test: -68.5554 [12.19], Avg: -25.4292 (0.323)
Ep: 341, Reward: -75.6551, Test: -74.1149 [7.49], Avg: -25.5935 (0.322)
Ep: 342, Reward: -74.5095, Test: -76.9708 [7.27], Avg: -25.7645 (0.321)
Ep: 343, Reward: -74.5546, Test: -71.1352 [10.19], Avg: -25.9260 (0.320)
Ep: 344, Reward: -75.4654, Test: -73.2996 [7.47], Avg: -26.0849 (0.319)
Ep: 345, Reward: -72.0737, Test: -74.3777 [6.43], Avg: -26.2431 (0.318)
Ep: 346, Reward: -73.1125, Test: -68.9001 [9.89], Avg: -26.3945 (0.317)
Ep: 347, Reward: -70.7135, Test: -77.1662 [4.62], Avg: -26.5537 (0.316)
Ep: 348, Reward: -73.4331, Test: -68.6891 [10.96], Avg: -26.7058 (0.315)
Ep: 349, Reward: -63.2409, Test: -73.8068 [10.20], Avg: -26.8695 (0.315)
Ep: 350, Reward: -70.8650, Test: -69.6477 [10.18], Avg: -27.0204 (0.314)
Ep: 351, Reward: -72.7498, Test: -76.0124 [5.54], Avg: -27.1753 (0.313)
Ep: 352, Reward: -82.7685, Test: -75.2812 [4.43], Avg: -27.3242 (0.312)
Ep: 353, Reward: -77.8159, Test: -74.4162 [8.97], Avg: -27.4825 (0.311)
Ep: 354, Reward: -78.7509, Test: -75.2542 [6.72], Avg: -27.6360 (0.310)
Ep: 355, Reward: -72.8759, Test: -74.1390 [9.15], Avg: -27.7924 (0.309)
Ep: 356, Reward: -77.7191, Test: -76.8175 [5.98], Avg: -27.9465 (0.308)
Ep: 357, Reward: -68.0481, Test: -68.6957 [16.68], Avg: -28.1069 (0.307)
Ep: 358, Reward: -100.0775, Test: -76.3455 [14.04], Avg: -28.2804 (0.306)
Ep: 359, Reward: -100.8024, Test: -61.1405 [29.49], Avg: -28.4536 (0.305)
Ep: 360, Reward: -75.7781, Test: -59.4700 [28.49], Avg: -28.6184 (0.304)
Ep: 361, Reward: -109.4255, Test: -64.7410 [39.13], Avg: -28.8263 (0.303)
Ep: 362, Reward: -89.7886, Test: -72.0669 [14.86], Avg: -28.9863 (0.302)
Ep: 363, Reward: -70.8049, Test: -65.5572 [25.43], Avg: -29.1566 (0.302)
Ep: 364, Reward: -73.4560, Test: -71.5267 [9.43], Avg: -29.2986 (0.301)
Ep: 365, Reward: -79.0222, Test: -76.3420 [13.13], Avg: -29.4630 (0.300)
Ep: 366, Reward: -74.5984, Test: -24.4378 [57.53], Avg: -29.6060 (0.299)
Ep: 367, Reward: -88.2300, Test: -51.9535 [18.21], Avg: -29.7162 (0.298)
Ep: 368, Reward: -57.3310, Test: -70.0203 [9.60], Avg: -29.8515 (0.297)
Ep: 369, Reward: -73.4011, Test: -28.2899 [45.97], Avg: -29.9715 (0.296)
Ep: 370, Reward: -62.8627, Test: -51.7202 [24.17], Avg: -30.0953 (0.295)
Ep: 371, Reward: -93.9835, Test: -27.8941 [33.34], Avg: -30.1790 (0.294)
Ep: 372, Reward: -60.8753, Test: -40.5122 [25.57], Avg: -30.2752 (0.294)
Ep: 373, Reward: -42.4027, Test: -64.2435 [17.99], Avg: -30.4141 (0.293)
Ep: 374, Reward: -72.7928, Test: -75.3357 [10.39], Avg: -30.5616 (0.292)
Ep: 375, Reward: -79.0155, Test: -56.9308 [26.39], Avg: -30.7020 (0.291)
Ep: 376, Reward: -81.3225, Test: -49.7939 [47.13], Avg: -30.8776 (0.290)
Ep: 377, Reward: -83.6420, Test: -52.7332 [44.75], Avg: -31.0538 (0.289)
Ep: 378, Reward: -77.6337, Test: -32.8129 [39.12], Avg: -31.1617 (0.288)
Ep: 379, Reward: -78.8402, Test: -30.9054 [44.76], Avg: -31.2788 (0.287)
Ep: 380, Reward: -56.7416, Test: -29.9498 [43.21], Avg: -31.3887 (0.287)
Ep: 381, Reward: -34.8589, Test: 14.1915 [57.01], Avg: -31.4186 (0.286)
Ep: 382, Reward: 10.6876, Test: 53.4768 [81.86], Avg: -31.4107 (0.285)
Ep: 383, Reward: -16.5952, Test: 21.5001 [82.88], Avg: -31.4887 (0.284)
Ep: 384, Reward: -0.6829, Test: 50.9718 [104.44], Avg: -31.5458 (0.283)
Ep: 385, Reward: 16.0858, Test: 76.1301 [77.11], Avg: -31.4666 (0.282)
Ep: 386, Reward: 23.1288, Test: 77.3601 [98.88], Avg: -31.4409 (0.281)
Ep: 387, Reward: 61.4596, Test: 107.8036 [121.33], Avg: -31.3948 (0.281)
Ep: 388, Reward: 96.4186, Test: 101.5569 [195.15], Avg: -31.5546 (0.280)
Ep: 389, Reward: 92.2508, Test: 277.0546 [244.18], Avg: -31.3894 (0.279)
Ep: 390, Reward: 122.2394, Test: 215.3588 [168.31], Avg: -31.1888 (0.278)
Ep: 391, Reward: 188.7286, Test: 176.6272 [84.77], Avg: -30.8750 (0.277)
Ep: 392, Reward: 135.1346, Test: 165.7874 [133.10], Avg: -30.7132 (0.276)
Ep: 393, Reward: 133.8665, Test: 213.1722 [172.67], Avg: -30.5325 (0.276)
Ep: 394, Reward: 191.3995, Test: 256.6196 [170.04], Avg: -30.2360 (0.275)
Ep: 395, Reward: 172.6204, Test: 257.6047 [129.48], Avg: -29.8361 (0.274)
Ep: 396, Reward: 146.8468, Test: 189.6140 [155.51], Avg: -29.6750 (0.273)
Ep: 397, Reward: 214.7980, Test: 375.6292 [233.57], Avg: -29.2436 (0.272)
Ep: 398, Reward: 332.5423, Test: 305.8367 [81.63], Avg: -28.6083 (0.271)
Ep: 399, Reward: 336.8078, Test: 265.9573 [157.38], Avg: -28.2654 (0.271)
Ep: 400, Reward: 365.2167, Test: 240.4297 [174.63], Avg: -28.0308 (0.270)
Ep: 401, Reward: 311.3462, Test: 157.5731 [141.79], Avg: -27.9218 (0.269)
Ep: 402, Reward: 204.9542, Test: 140.5101 [89.79], Avg: -27.7267 (0.268)
Ep: 403, Reward: 330.8280, Test: 124.3780 [83.84], Avg: -27.5577 (0.267)
Ep: 404, Reward: 411.2644, Test: 148.3290 [204.42], Avg: -27.6281 (0.267)
Ep: 405, Reward: 184.2705, Test: 325.1509 [224.39], Avg: -27.3119 (0.266)
Ep: 406, Reward: 377.5507, Test: 181.3088 [183.69], Avg: -27.2506 (0.265)
Ep: 407, Reward: 220.5734, Test: 281.2694 [243.61], Avg: -27.0915 (0.264)
Ep: 408, Reward: 201.4341, Test: 314.7510 [215.22], Avg: -26.7819 (0.263)
Ep: 409, Reward: 414.9546, Test: 261.2522 [220.43], Avg: -26.6171 (0.263)
Ep: 410, Reward: 394.5611, Test: 366.5063 [237.63], Avg: -26.2387 (0.262)
Ep: 411, Reward: 297.1816, Test: 206.7929 [151.29], Avg: -26.0403 (0.261)
Ep: 412, Reward: 403.6707, Test: 277.1623 [199.06], Avg: -25.7882 (0.260)
Ep: 413, Reward: 326.6657, Test: 283.8840 [236.53], Avg: -25.6115 (0.259)
Ep: 414, Reward: 382.9269, Test: 165.3197 [136.18], Avg: -25.4796 (0.259)
Ep: 415, Reward: 282.0946, Test: 237.5280 [67.41], Avg: -25.0094 (0.258)
Ep: 416, Reward: 310.9790, Test: 244.0555 [262.21], Avg: -24.9930 (0.257)
Ep: 417, Reward: 258.2444, Test: 186.5186 [190.23], Avg: -24.9421 (0.256)
Ep: 418, Reward: 193.1707, Test: 124.5344 [140.29], Avg: -24.9201 (0.256)
Ep: 419, Reward: 18.7983, Test: 8.2515 [92.09], Avg: -25.0604 (0.255)
Ep: 420, Reward: 2.5437, Test: -8.0130 [62.97], Avg: -25.1695 (0.254)
Ep: 421, Reward: -32.2377, Test: -50.6941 [45.85], Avg: -25.3386 (0.253)
Ep: 422, Reward: -45.2411, Test: -28.0606 [56.91], Avg: -25.4796 (0.253)
Ep: 423, Reward: -36.5878, Test: 23.8101 [124.32], Avg: -25.6566 (0.252)
Ep: 424, Reward: 58.6387, Test: 33.3828 [71.23], Avg: -25.6852 (0.251)
Ep: 425, Reward: -15.8857, Test: -32.0432 [60.33], Avg: -25.8418 (0.250)
Ep: 426, Reward: 110.1593, Test: 23.0078 [116.06], Avg: -25.9992 (0.250)
Ep: 427, Reward: 45.2726, Test: 61.9652 [94.15], Avg: -26.0136 (0.249)
Ep: 428, Reward: 12.4418, Test: -8.8914 [60.40], Avg: -26.1145 (0.248)
Ep: 429, Reward: -21.3335, Test: -42.8275 [33.32], Avg: -26.2308 (0.247)
Ep: 430, Reward: 16.3012, Test: 84.7373 [123.66], Avg: -26.2603 (0.247)
Ep: 431, Reward: 85.4105, Test: 95.2754 [84.85], Avg: -26.1754 (0.246)
Ep: 432, Reward: 120.7813, Test: 102.5079 [124.00], Avg: -26.1646 (0.245)
Ep: 433, Reward: -22.2831, Test: -39.7855 [25.51], Avg: -26.2547 (0.244)
Ep: 434, Reward: -15.0414, Test: -36.0705 [37.33], Avg: -26.3631 (0.244)
Ep: 435, Reward: -31.7223, Test: -50.6487 [10.57], Avg: -26.4431 (0.243)
Ep: 436, Reward: -36.3099, Test: -51.0288 [22.51], Avg: -26.5508 (0.242)
Ep: 437, Reward: -28.0133, Test: -47.7656 [13.57], Avg: -26.6302 (0.241)
Ep: 438, Reward: -44.3782, Test: -54.4606 [13.48], Avg: -26.7243 (0.241)
Ep: 439, Reward: -54.6732, Test: -23.5797 [57.48], Avg: -26.8478 (0.240)
Ep: 440, Reward: -44.5618, Test: -18.1281 [41.84], Avg: -26.9229 (0.239)
Ep: 441, Reward: -16.7523, Test: -46.6942 [19.21], Avg: -27.0111 (0.239)
Ep: 442, Reward: 2.9444, Test: -28.6530 [27.66], Avg: -27.0772 (0.238)
Ep: 443, Reward: -45.1879, Test: -27.9650 [69.31], Avg: -27.2353 (0.237)
Ep: 444, Reward: -35.2027, Test: -42.3436 [42.97], Avg: -27.3658 (0.236)
Ep: 445, Reward: -45.3940, Test: -20.0961 [38.74], Avg: -27.4364 (0.236)
Ep: 446, Reward: 4.3981, Test: -17.9272 [56.31], Avg: -27.5411 (0.235)
Ep: 447, Reward: -24.4723, Test: 11.3333 [41.89], Avg: -27.5478 (0.234)
Ep: 448, Reward: -29.0794, Test: -45.2411 [37.27], Avg: -27.6702 (0.234)
Ep: 449, Reward: -2.2830, Test: -28.9244 [43.13], Avg: -27.7689 (0.233)
Ep: 450, Reward: -17.5429, Test: -11.0207 [63.63], Avg: -27.8728 (0.232)
Ep: 451, Reward: 2.9322, Test: 59.7908 [98.59], Avg: -27.8970 (0.231)
Ep: 452, Reward: 217.1030, Test: 164.9234 [40.61], Avg: -27.5610 (0.231)
Ep: 453, Reward: 205.7236, Test: 101.1264 [118.21], Avg: -27.5379 (0.230)
Ep: 454, Reward: 196.2527, Test: 158.8273 [98.41], Avg: -27.3446 (0.229)
Ep: 455, Reward: 161.3498, Test: 109.2658 [46.15], Avg: -27.1462 (0.229)
Ep: 456, Reward: 194.1521, Test: -5.9964 [72.82], Avg: -27.2593 (0.228)
Ep: 457, Reward: 20.5569, Test: 38.0658 [68.12], Avg: -27.2654 (0.227)
Ep: 458, Reward: 50.2073, Test: 75.2691 [102.88], Avg: -27.2661 (0.227)
Ep: 459, Reward: 46.1375, Test: 77.5571 [49.86], Avg: -27.1466 (0.226)
Ep: 460, Reward: 49.6694, Test: 9.5476 [61.15], Avg: -27.1997 (0.225)
Ep: 461, Reward: 108.1756, Test: 235.1180 [250.67], Avg: -27.1745 (0.225)
Ep: 462, Reward: 167.8197, Test: 125.6684 [105.09], Avg: -27.0713 (0.224)
Ep: 463, Reward: 289.3401, Test: 39.1384 [65.84], Avg: -27.0705 (0.223)
Ep: 464, Reward: 27.7981, Test: 19.7397 [79.61], Avg: -27.1411 (0.223)
Ep: 465, Reward: -1.9219, Test: -0.3169 [47.05], Avg: -27.1845 (0.222)
Ep: 466, Reward: 56.4407, Test: -60.8640 [19.81], Avg: -27.2990 (0.221)
Ep: 467, Reward: -61.9375, Test: -68.3792 [16.50], Avg: -27.4221 (0.220)
Ep: 468, Reward: -58.3059, Test: -57.5190 [18.15], Avg: -27.5249 (0.219)
Ep: 469, Reward: -68.1041, Test: -61.8766 [16.82], Avg: -27.6338 (0.219)
Ep: 470, Reward: -64.7143, Test: -55.8466 [20.74], Avg: -27.7378 (0.218)
Ep: 471, Reward: -67.8984, Test: -53.9129 [16.93], Avg: -27.8291 (0.217)
Ep: 472, Reward: -60.9592, Test: -60.4472 [22.53], Avg: -27.9457 (0.217)
Ep: 473, Reward: -55.3150, Test: -52.9230 [16.83], Avg: -28.0339 (0.216)
Ep: 474, Reward: -64.2700, Test: -66.5030 [18.37], Avg: -28.1535 (0.215)
Ep: 475, Reward: -67.2239, Test: -52.1427 [16.69], Avg: -28.2390 (0.215)
Ep: 476, Reward: -47.4186, Test: -44.9029 [30.24], Avg: -28.3373 (0.214)
Ep: 477, Reward: -59.4972, Test: -38.4930 [15.45], Avg: -28.3909 (0.213)
Ep: 478, Reward: -50.1963, Test: -53.6449 [19.70], Avg: -28.4847 (0.213)
Ep: 479, Reward: -52.4755, Test: -54.3613 [14.75], Avg: -28.5694 (0.212)
Ep: 480, Reward: -55.1610, Test: -67.1816 [22.77], Avg: -28.6970 (0.212)
Ep: 481, Reward: -51.3871, Test: -47.4960 [22.06], Avg: -28.7817 (0.211)
Ep: 482, Reward: -47.2056, Test: -25.8022 [28.02], Avg: -28.8336 (0.210)
Ep: 483, Reward: -50.6981, Test: -30.8120 [40.32], Avg: -28.9210 (0.210)
Ep: 484, Reward: -35.9214, Test: 0.3166 [28.20], Avg: -28.9188 (0.209)
Ep: 485, Reward: -19.4293, Test: 63.6304 [145.59], Avg: -29.0280 (0.208)
Ep: 486, Reward: -17.0713, Test: -1.2903 [58.60], Avg: -29.0914 (0.208)
Ep: 487, Reward: -11.6388, Test: 65.6308 [116.09], Avg: -29.1352 (0.207)
Ep: 488, Reward: 33.2845, Test: 24.5642 [65.16], Avg: -29.1586 (0.207)
Ep: 489, Reward: 4.2448, Test: 74.9782 [126.01], Avg: -29.2032 (0.206)
Ep: 490, Reward: 24.5440, Test: 110.9082 [77.98], Avg: -29.0767 (0.205)
Ep: 491, Reward: 58.5774, Test: 98.2974 [103.48], Avg: -29.0281 (0.205)
Ep: 492, Reward: 15.3442, Test: 43.3431 [86.14], Avg: -29.0561 (0.204)
Ep: 493, Reward: -16.1217, Test: 39.6203 [68.75], Avg: -29.0562 (0.203)
Ep: 494, Reward: 26.4129, Test: 86.8567 [95.62], Avg: -29.0152 (0.203)
Ep: 495, Reward: 24.0615, Test: 38.9385 [86.84], Avg: -29.0533 (0.202)
Ep: 496, Reward: 77.6373, Test: 89.1411 [122.86], Avg: -29.0626 (0.202)
Ep: 497, Reward: 228.7484, Test: 146.7482 [102.93], Avg: -28.9163 (0.201)
Ep: 498, Reward: 158.0976, Test: 195.7381 [178.50], Avg: -28.8238 (0.200)
Ep: 499, Reward: 170.7745, Test: 179.5320 [109.89], Avg: -28.6269 (0.200)
