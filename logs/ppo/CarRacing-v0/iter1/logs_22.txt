Model: <class 'models.ppo.PPOAgent'>, Dir: iter1/
statemodel: <class 'utils.envs.WorldModel'>, num_envs: 16,

import gym
import torch
import pickle
import argparse
import numpy as np
from models.rand import ReplayBuffer, PrioritizedReplayBuffer
from utils.network import PTACNetwork, PTACAgent, Conv, INPUT_LAYER, ACTOR_HIDDEN, CRITIC_HIDDEN, LEARN_RATE, DISCOUNT_RATE, NUM_STEPS, ADVANTAGE_DECAY

EPS_MIN = 0.1                 	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
BATCH_SIZE = 4					# Number of samples to train on for each train step
PPO_EPOCHS = 2					# Number of iterations to sample batches for training
ENTROPY_WEIGHT = 0.005			# The weight for the entropy term of the Actor loss
CLIP_PARAM = 0.01				# The limit of the ratio of new action probabilities to old probabilities

class PPOActor(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, ACTOR_HIDDEN)
		self.layer3 = torch.nn.Linear(ACTOR_HIDDEN, ACTOR_HIDDEN)
		self.action_mu = torch.nn.Linear(ACTOR_HIDDEN, *action_size)
		self.action_sig = torch.nn.Parameter(torch.zeros(*action_size))
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)
		
	def forward(self, state, action=None, sample=True):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu()
		action_mu = self.action_mu(state)
		action_sig = self.action_sig.exp().expand_as(action_mu)
		dist = torch.distributions.Normal(action_mu, action_sig)
		action = action_mu if not sample else dist.sample() if action is None else action
		log_prob = dist.log_prob(action)
		entropy = dist.entropy()
		return action, log_prob, entropy

class PPOCritic(torch.nn.Module):
	def __init__(self, state_size, action_size):
		super().__init__()
		self.layer1 = torch.nn.Linear(state_size[-1], INPUT_LAYER) if len(state_size)==1 else Conv(state_size, INPUT_LAYER)
		self.layer2 = torch.nn.Linear(INPUT_LAYER, CRITIC_HIDDEN)
		self.layer3 = torch.nn.Linear(CRITIC_HIDDEN, CRITIC_HIDDEN)
		self.value = torch.nn.Linear(CRITIC_HIDDEN, 1)
		self.apply(lambda m: torch.nn.init.xavier_normal_(m.weight) if type(m) in [torch.nn.Conv2d, torch.nn.Linear] else None)

	def forward(self, state):
		state = self.layer1(state).relu()
		state = self.layer2(state).relu()
		state = self.layer3(state).relu() + state
		value = self.value(state)
		return value

class PPONetwork(PTACNetwork):
	def __init__(self, state_size, action_size, lr=LEARN_RATE, gpu=True, load=None):
		super().__init__(state_size, action_size, PPOActor, PPOCritic, lr=lr, gpu=gpu, load=load)

	def get_action_probs(self, state, action_in=None, sample=True, grad=True):
		with torch.enable_grad() if grad else torch.no_grad():
			action, log_prob, entropy = self.actor_local(state.to(self.device), action_in, sample)
			return action if action_in is None else entropy.mean(), log_prob

	def get_value(self, state, grad=True, use_target=False):
		with torch.enable_grad() if grad else torch.no_grad():
			critic = self.critic_local if not use_target else self.critic_target
			return critic(state.to(self.device))

	def optimize(self, states, actions, old_log_probs, targets, advantages, importances=torch.scalar_tensor(1), clip_param=CLIP_PARAM, e_weight=ENTROPY_WEIGHT, scale=1):
		values = self.get_value(states)
		critic_error = values - targets
		critic_loss = importances.to(self.device) + critic_error.pow(2)
		self.step(self.critic_optimizer, critic_loss.mean())
		self.soft_copy(self.critic_local, self.critic_target)

		entropy, new_log_probs = self.get_action_probs(states, actions)
		ratio = (new_log_probs - old_log_probs).exp()
		ratio_clipped = torch.clamp(ratio, 1.0-clip_param, 1.0+clip_param)
		actor_loss = -(torch.min(ratio*advantages, ratio_clipped*advantages).mean() + e_weight*entropy) * scale
		self.step(self.actor_optimizer, actor_loss)
		return critic_error.cpu().detach().numpy().squeeze(-1)

	def save_model(self, dirname="pytorch", name="best"):
		super().save_model("ppo", dirname, name)
		
	def load_model(self, dirname="pytorch", name="best"):
		super().load_model("ppo", dirname, name)

class PPOAgent(PTACAgent):
	def __init__(self, state_size, action_size, decay=EPS_DECAY, lr=LEARN_RATE, update_freq=NUM_STEPS, gpu=True, load=None):
		super().__init__(state_size, action_size, PPONetwork, lr=lr, update_freq=update_freq, decay=decay, gpu=gpu, load=load)
		self.ppo_epochs = PPO_EPOCHS
		self.ppo_batch = BATCH_SIZE

	def get_action(self, state, eps=None, sample=True):
		state = self.to_tensor(state)
		self.action, self.log_prob = [x.cpu().numpy() for x in self.network.get_action_probs(state, sample=sample, grad=False)]
		return np.tanh(self.action)

	def train(self, state, action, next_state, reward, done):
		self.buffer.append((state, self.action, self.log_prob, reward, done))
		update_freq = int(self.update_freq * (1 - self.eps + EPS_MIN)**2)
		if len(self.buffer) >= update_freq:
			states, actions, log_probs, rewards, dones = map(self.to_tensor, zip(*self.buffer))
			self.buffer.clear()
			next_state = self.to_tensor(next_state)
			values = self.network.get_value(states, grad=False, use_target=True)
			next_value = self.network.get_value(next_state, grad=False, use_target=True)
			targets, advantages = self.compute_gae(next_value, rewards.unsqueeze(-1), dones.unsqueeze(-1), values, gamma=DISCOUNT_RATE, lamda=ADVANTAGE_DECAY)
			states, actions, log_probs, targets, advantages = [x.view(x.size(0)*x.size(1), *x.size()[2:]) for x in (states, actions, log_probs, targets, advantages)]
			self.replay_buffer.clear().extend(zip(states, actions, log_probs, targets, advantages))
			for _ in range(self.ppo_epochs):
				for i in range(0, len(self.replay_buffer), self.ppo_batch):
					state, action, log_prob, target, advantage = self.replay_buffer.index(self.ppo_batch, i, torch.stack)
					self.network.optimize(state, action, log_prob, target, advantage, e_weight=self.eps*ENTROPY_WEIGHT, scale=16*update_freq/len(self.replay_buffer))
		# if len(self.replay_buffer) > 0:
		# 	(states, actions, log_probs, targets, advantages), indices, importances = self.replay_buffer.sample(BATCH_SIZE, dtype=self.to_tensor)
		# 	errors = self.network.optimize(states, actions, log_probs, targets, advantages, importances**(1-self.eps))
		# 	self.replay_buffer.update_priorities(indices, errors)
		if done[0]: self.eps = max(self.eps * self.decay, EPS_MIN)

REG_LAMBDA = 1e-6             	# Penalty multiplier to apply for the size of the network weights
LEARN_RATE = 0.0001           	# Sets how much we want to update the network weights at each training step
TARGET_UPDATE_RATE = 0.0004   	# How frequently we want to copy the local network to the target network (for double DQNs)
INPUT_LAYER = 512				# The number of output nodes from the first layer to Actor and Critic networks
ACTOR_HIDDEN = 256				# The number of nodes in the hidden layers of the Actor network
CRITIC_HIDDEN = 1024			# The number of nodes in the hidden layers of the Critic networks
DISCOUNT_RATE = 0.99			# The discount rate to use in the Bellman Equation
NUM_STEPS = 1000				# The number of steps to collect experience in sequence for each GAE calculation
EPS_MAX = 1.0                 	# The starting proportion of random to greedy actions to take
EPS_MIN = 0.020               	# The lower limit proportion of random to greedy actions to take
EPS_DECAY = 0.995             	# The rate at which eps decays from EPS_MAX to EPS_MIN
ADVANTAGE_DECAY = 0.95			# The discount factor for the cumulative GAE calculation
MAX_BUFFER_SIZE = 100000      	# Sets the maximum length of the replay buffer

import os
import gym
import torch
import argparse
import numpy as np
from collections import deque
from models.ppo import PPOAgent
from models.rand import RandomAgent
from models.ddpg import DDPGAgent, EPS_MIN
from utils.envs import EnsembleEnv, EnvManager, EnvWorker, WorldModel, ImgStack
from utils.misc import Logger, rollout

parser = argparse.ArgumentParser(description="A3C Trainer")
parser.add_argument("--workerports", type=int, default=[16], nargs="+", help="The list of worker ports to connect to")
parser.add_argument("--selfport", type=int, default=None, help="Which port to listen on (as a worker server)")
parser.add_argument("--iternum", type=int, default=-1, choices=[-1,0,1], help="Whether to train using World Model to load (0 or 1) or raw images (-1)")
parser.add_argument("--model", type=str, default="ppo", choices=["ddpg", "ppo"], help="Which reinforcement learning algorithm to use")
parser.add_argument("--runs", type=int, default=1, help="Number of episodes to train the agent")
parser.add_argument("--trial", action="store_true", help="Whether to show a trial run training on the Pendulum-v0 environment")
args = parser.parse_args()

ENV_NAME = "CarRacing-v0"

class WorldACAgent(RandomAgent):
	def __init__(self, action_size, num_envs, acagent, statemodel=WorldModel, load="", gpu=True, train=True):
		super().__init__(action_size)
		self.world_model = statemodel(action_size, num_envs, load=load, gpu=gpu)
		self.acagent = acagent(self.world_model.state_size, action_size, load="" if train else load, gpu=gpu)

	def get_env_action(self, env, state, eps=None, sample=True):
		state, latent = self.world_model.get_state(state)
		env_action, action = self.acagent.get_env_action(env, state, eps, sample)
		self.world_model.step(latent, env_action)
		return env_action, action, state

	def train(self, state, action, next_state, reward, done):
		next_state = self.world_model.get_state(next_state)[0]
		self.acagent.train(state, action, next_state, reward, done)

	def reset(self, num_envs=None):
		num_envs = self.world_model.num_envs if num_envs is None else num_envs
		self.world_model.reset(num_envs, restore=False)
		return self

	def save_model(self, dirname="pytorch", name="best"):
		self.acagent.network.save_model(dirname, name)

	def load(self, dirname="pytorch", name="best"):
		self.world_model.load_model(dirname, name)
		self.acagent.network.load_model(dirname, name)
		return self

def run(model, statemodel, runs=1, load_dir="", ports=16):
	num_envs = len(ports) if type(ports) == list else min(ports, 16)
	logger = Logger(model, load_dir, statemodel=statemodel, num_envs=num_envs)
	envs = EnvManager(ENV_NAME, ports) if type(ports) == list else EnsembleEnv(ENV_NAME, ports)
	agent = WorldACAgent(envs.action_size, num_envs, model, statemodel, load=load_dir)
	total_rewards = []
	for ep in range(runs):
		states = envs.reset()
		agent.reset(num_envs)
		total_reward = 0
		for _ in range(envs.env.spec.max_episode_steps):
			env_actions, actions, states = agent.get_env_action(envs.env, states)
			next_states, rewards, dones, _ = envs.step(env_actions, render=(ep%runs==0))
			agent.train(states, actions, next_states, rewards, dones)
			total_reward += np.mean(rewards)
			states = next_states
		rollouts = [rollout(envs.env, agent.reset(1)) for _ in range(10)]
		test_reward = np.mean(rollouts) - np.std(rollouts)
		total_rewards.append(test_reward)
		agent.save_model(load_dir, "checkpoint")
		if total_rewards[-1] >= max(total_rewards): agent.save_model(load_dir)
		logger.log(f"Ep: {ep}, Reward: {total_reward:.4f}, Test: {test_reward+np.std(rollouts):.4f} [{np.std(rollouts):.2f}], Avg: {np.mean(total_rewards):.4f} ({agent.acagent.eps:.3f})")
	envs.close()

def trial(model, steps=40000, ports=16):
	env_name = "Pendulum-v0"
	envs = EnvManager(ENV_NAME, ports) if type(ports) == list else EnsembleEnv(ENV_NAME, ports)
	agent = model(envs.state_size, envs.action_size, decay=0.99)
	env = gym.make(env_name)
	state = envs.reset()
	test_rewards = []
	for s in range(steps):
		env_action, action = agent.get_env_action(env, state)
		next_state, reward, done, _ = envs.step(env_action)
		agent.train(state, action, next_state, reward, done)
		state = next_state
		if s % env.spec.max_episode_steps == 0:
			test_reward = np.mean([rollout(env, agent) for _ in range(10)])
			test_rewards.append(test_reward)
			print(f"Ep: {s//env.spec.max_episode_steps}, Rewards: {test_reward}, Avg: {np.mean(test_rewards)}")
			if test_reward > -200: break
	env.close()
	envs.close()

if __name__ == "__main__":
	dirname = "pytorch" if args.iternum < 0 else f"iter{args.iternum}/"
	state = ImgStack if args.iternum < 0 else WorldModel
	model = PPOAgent if args.model == "ppo" else DDPGAgent
	if args.trial:
		trial(model, ports=args.workerports)
	elif args.selfport is not None:
		EnvWorker(args.selfport, ENV_NAME).start()
	else:
		if len(args.workerports) == 1: args.workerports = args.workerports[0]
		run(model, state, args.runs, dirname, args.workerports)

Ep: 0, Reward: -25.2210, Test: -17.4305 [27.52], Avg: -44.9517 (0.995)
Ep: 1, Reward: -22.3732, Test: -53.0041 [54.57], Avg: -76.2628 (0.990)
Ep: 2, Reward: -22.2340, Test: -4.6989 [63.16], Avg: -73.4622 (0.985)
Ep: 3, Reward: -28.9532, Test: -108.7723 [40.76], Avg: -92.4801 (0.980)
Ep: 4, Reward: -45.0387, Test: -54.5132 [44.11], Avg: -93.7077 (0.975)
Ep: 5, Reward: -43.3301, Test: -84.7548 [1.29], Avg: -92.4303 (0.970)
Ep: 6, Reward: -68.3008, Test: -83.9087 [1.67], Avg: -91.4510 (0.966)
Ep: 7, Reward: -67.4100, Test: -85.9377 [2.01], Avg: -91.0130 (0.961)
Ep: 8, Reward: -73.0031, Test: -78.1262 [3.08], Avg: -89.9238 (0.956)
Ep: 9, Reward: -77.3012, Test: -82.4227 [3.26], Avg: -89.4994 (0.951)
Ep: 10, Reward: -75.3011, Test: -82.9499 [3.58], Avg: -89.2292 (0.946)
Ep: 11, Reward: -75.9336, Test: -86.0199 [0.89], Avg: -89.0362 (0.942)
Ep: 12, Reward: -76.6718, Test: -86.3369 [0.59], Avg: -88.8741 (0.937)
Ep: 13, Reward: -72.9918, Test: -86.2136 [1.76], Avg: -88.8101 (0.932)
Ep: 14, Reward: -70.7598, Test: -86.2465 [0.66], Avg: -88.6835 (0.928)
Ep: 15, Reward: -72.9932, Test: -83.6750 [2.00], Avg: -88.4952 (0.923)
Ep: 16, Reward: -70.1882, Test: -83.6074 [2.15], Avg: -88.3339 (0.918)
Ep: 17, Reward: -69.9457, Test: -83.2095 [1.20], Avg: -88.1160 (0.914)
Ep: 18, Reward: -69.7015, Test: -83.0735 [1.71], Avg: -87.9404 (0.909)
Ep: 19, Reward: -66.9803, Test: -84.2071 [1.84], Avg: -87.8455 (0.905)
Ep: 20, Reward: -74.4152, Test: -83.8706 [1.84], Avg: -87.7438 (0.900)
Ep: 21, Reward: -74.9779, Test: -82.8633 [1.70], Avg: -87.5991 (0.896)
Ep: 22, Reward: -73.3306, Test: -83.3316 [1.71], Avg: -87.4878 (0.891)
Ep: 23, Reward: -71.1623, Test: -82.6350 [1.06], Avg: -87.3296 (0.887)
Ep: 24, Reward: -70.2528, Test: -83.9218 [1.48], Avg: -87.2527 (0.882)
Ep: 25, Reward: -68.4419, Test: -83.6117 [1.44], Avg: -87.1682 (0.878)
Ep: 26, Reward: -65.5221, Test: -82.9976 [1.61], Avg: -87.0732 (0.873)
Ep: 27, Reward: -67.5918, Test: -83.7080 [1.52], Avg: -87.0074 (0.869)
Ep: 28, Reward: -64.4832, Test: -83.4934 [1.28], Avg: -86.9303 (0.865)
Ep: 29, Reward: -70.3924, Test: -83.9533 [2.47], Avg: -86.9134 (0.860)
Ep: 30, Reward: -69.8364, Test: -82.5750 [1.33], Avg: -86.8163 (0.856)
Ep: 31, Reward: -72.4040, Test: -82.9608 [1.40], Avg: -86.7397 (0.852)
Ep: 32, Reward: -69.8788, Test: -83.7150 [1.33], Avg: -86.6882 (0.848)
Ep: 33, Reward: -66.0278, Test: -83.0227 [1.99], Avg: -86.6389 (0.843)
Ep: 34, Reward: -65.7842, Test: -82.5838 [1.55], Avg: -86.5673 (0.839)
Ep: 35, Reward: -64.9296, Test: -82.9043 [1.07], Avg: -86.4951 (0.835)
Ep: 36, Reward: -46.7510, Test: -82.3016 [2.66], Avg: -86.4537 (0.831)
Ep: 37, Reward: -44.1183, Test: -82.4041 [1.45], Avg: -86.3854 (0.827)
Ep: 38, Reward: -39.8167, Test: -80.0008 [6.70], Avg: -86.3934 (0.822)
Ep: 39, Reward: -41.2247, Test: -83.3600 [1.02], Avg: -86.3430 (0.818)
Ep: 40, Reward: -44.2145, Test: -83.4995 [0.99], Avg: -86.2978 (0.814)
Ep: 41, Reward: -54.8259, Test: -83.3993 [0.92], Avg: -86.2507 (0.810)
Ep: 42, Reward: -35.3043, Test: -83.5018 [1.32], Avg: -86.2176 (0.806)
Ep: 43, Reward: -21.7734, Test: -79.8369 [5.98], Avg: -86.2085 (0.802)
Ep: 44, Reward: -18.0073, Test: -80.9158 [6.59], Avg: -86.2373 (0.798)
Ep: 45, Reward: -0.8555, Test: -71.3431 [10.47], Avg: -86.1411 (0.794)
Ep: 46, Reward: -3.7408, Test: -75.5997 [8.11], Avg: -86.0895 (0.790)
Ep: 47, Reward: 3.8736, Test: -68.8901 [6.58], Avg: -85.8683 (0.786)
Ep: 48, Reward: 16.3130, Test: -68.0577 [7.29], Avg: -85.6537 (0.782)
Ep: 49, Reward: 12.2792, Test: -70.5932 [2.40], Avg: -85.4004 (0.778)
Ep: 50, Reward: 7.1555, Test: -66.8039 [4.83], Avg: -85.1304 (0.774)
Ep: 51, Reward: 6.1669, Test: -72.1685 [2.66], Avg: -84.9324 (0.771)
Ep: 52, Reward: 7.6763, Test: -71.9447 [3.13], Avg: -84.7465 (0.767)
Ep: 53, Reward: 17.8667, Test: -66.8486 [10.10], Avg: -84.6021 (0.763)
Ep: 54, Reward: 28.2351, Test: -71.0573 [5.33], Avg: -84.4526 (0.759)
Ep: 55, Reward: 27.4564, Test: -68.7690 [8.34], Avg: -84.3214 (0.755)
Ep: 56, Reward: 71.2786, Test: -70.3310 [5.25], Avg: -84.1680 (0.751)
Ep: 57, Reward: 39.6416, Test: -68.9683 [8.32], Avg: -84.0494 (0.748)
Ep: 58, Reward: 0.2645, Test: -69.6056 [4.19], Avg: -83.8756 (0.744)
Ep: 59, Reward: 38.8973, Test: -69.2136 [8.13], Avg: -83.7667 (0.740)
Ep: 60, Reward: 40.8407, Test: -70.1285 [4.86], Avg: -83.6227 (0.737)
Ep: 61, Reward: 73.5984, Test: -67.4193 [6.64], Avg: -83.4685 (0.733)
Ep: 62, Reward: 55.5256, Test: -69.3584 [4.91], Avg: -83.3224 (0.729)
Ep: 63, Reward: 111.5352, Test: -71.0196 [3.45], Avg: -83.1840 (0.726)
Ep: 64, Reward: 94.6078, Test: -69.3477 [4.55], Avg: -83.0412 (0.722)
Ep: 65, Reward: 107.2441, Test: -62.1432 [12.67], Avg: -82.9165 (0.718)
Ep: 66, Reward: 137.1299, Test: -68.7597 [5.30], Avg: -82.7844 (0.715)
Ep: 67, Reward: 86.0915, Test: -56.8266 [11.21], Avg: -82.5674 (0.711)
Ep: 68, Reward: 147.3977, Test: -60.2971 [12.54], Avg: -82.4264 (0.708)
Ep: 69, Reward: 88.4808, Test: -60.8639 [15.24], Avg: -82.3360 (0.704)
Ep: 70, Reward: 160.0056, Test: -65.2741 [10.99], Avg: -82.2505 (0.701)
Ep: 71, Reward: 116.9405, Test: -59.1218 [14.19], Avg: -82.1263 (0.697)
Ep: 72, Reward: 117.4830, Test: -56.7256 [12.62], Avg: -81.9513 (0.694)
Ep: 73, Reward: 122.2381, Test: -64.4922 [8.27], Avg: -81.8272 (0.690)
Ep: 74, Reward: 109.5718, Test: -61.1668 [13.15], Avg: -81.7270 (0.687)
Ep: 75, Reward: 131.8928, Test: -56.8730 [12.00], Avg: -81.5579 (0.683)
Ep: 76, Reward: 95.5560, Test: -62.1206 [12.70], Avg: -81.4704 (0.680)
Ep: 77, Reward: 96.7713, Test: -66.1233 [5.48], Avg: -81.3440 (0.676)
Ep: 78, Reward: 98.9290, Test: -64.5805 [9.67], Avg: -81.2542 (0.673)
Ep: 79, Reward: 137.1334, Test: -43.0303 [30.56], Avg: -81.1585 (0.670)
Ep: 80, Reward: 121.0935, Test: -50.7834 [14.56], Avg: -80.9632 (0.666)
Ep: 81, Reward: 157.8356, Test: -54.6935 [15.97], Avg: -80.8375 (0.663)
Ep: 82, Reward: 129.5482, Test: -52.8957 [15.07], Avg: -80.6825 (0.660)
Ep: 83, Reward: 142.2173, Test: -35.6450 [16.08], Avg: -80.3378 (0.656)
Ep: 84, Reward: 120.0419, Test: -43.1354 [15.59], Avg: -80.0836 (0.653)
Ep: 85, Reward: 110.3221, Test: -38.7030 [20.88], Avg: -79.8453 (0.650)
Ep: 86, Reward: 143.9940, Test: -48.2150 [18.77], Avg: -79.6974 (0.647)
Ep: 87, Reward: 183.6568, Test: -48.6258 [13.41], Avg: -79.4967 (0.643)
Ep: 88, Reward: 117.6282, Test: -53.6302 [11.58], Avg: -79.3362 (0.640)
Ep: 89, Reward: 166.2542, Test: -46.5966 [15.62], Avg: -79.1460 (0.637)
Ep: 90, Reward: 111.9124, Test: -57.0550 [7.31], Avg: -78.9836 (0.634)
Ep: 91, Reward: 132.8123, Test: -50.0777 [19.06], Avg: -78.8765 (0.631)
Ep: 92, Reward: 114.7704, Test: -56.4326 [8.32], Avg: -78.7247 (0.627)
Ep: 93, Reward: 175.9517, Test: -53.3639 [10.64], Avg: -78.5680 (0.624)
Ep: 94, Reward: 126.9231, Test: -40.8284 [17.02], Avg: -78.3500 (0.621)
Ep: 95, Reward: 158.2173, Test: -46.6351 [18.54], Avg: -78.2127 (0.618)
Ep: 96, Reward: 88.6926, Test: -44.3349 [16.59], Avg: -78.0345 (0.615)
Ep: 97, Reward: 184.4404, Test: -52.7287 [11.76], Avg: -77.8963 (0.612)
Ep: 98, Reward: 160.6646, Test: -48.6284 [21.61], Avg: -77.8190 (0.609)
Ep: 99, Reward: 199.3478, Test: -36.8326 [29.79], Avg: -77.7070 (0.606)
Ep: 100, Reward: 156.5013, Test: -46.7190 [15.50], Avg: -77.5536 (0.603)
Ep: 101, Reward: 146.4345, Test: -44.2021 [17.60], Avg: -77.3992 (0.600)
Ep: 102, Reward: 172.6458, Test: -52.5120 [16.65], Avg: -77.3192 (0.597)
Ep: 103, Reward: 128.6577, Test: -44.5690 [20.90], Avg: -77.2052 (0.594)
Ep: 104, Reward: 158.1401, Test: -48.0144 [17.76], Avg: -77.0964 (0.591)
Ep: 105, Reward: 169.9317, Test: -36.7416 [20.99], Avg: -76.9137 (0.588)
Ep: 106, Reward: 190.8362, Test: -42.6609 [18.28], Avg: -76.7644 (0.585)
Ep: 107, Reward: 177.5649, Test: -44.8971 [16.94], Avg: -76.6263 (0.582)
Ep: 108, Reward: 218.0379, Test: -44.6574 [17.84], Avg: -76.4966 (0.579)
Ep: 109, Reward: 224.8903, Test: -41.7482 [13.25], Avg: -76.3011 (0.576)
Ep: 110, Reward: 232.8446, Test: -38.5724 [13.43], Avg: -76.0822 (0.573)
Ep: 111, Reward: 176.1071, Test: -48.2339 [17.81], Avg: -75.9927 (0.570)
Ep: 112, Reward: 225.2374, Test: -47.1350 [17.75], Avg: -75.8944 (0.568)
Ep: 113, Reward: 165.4300, Test: -39.5564 [26.06], Avg: -75.8042 (0.565)
Ep: 114, Reward: 196.0876, Test: -35.5288 [18.37], Avg: -75.6137 (0.562)
Ep: 115, Reward: 160.2631, Test: -34.3444 [15.64], Avg: -75.3927 (0.559)
Ep: 116, Reward: 244.5915, Test: -37.5382 [17.92], Avg: -75.2223 (0.556)
Ep: 117, Reward: 238.3393, Test: -44.0573 [11.82], Avg: -75.0584 (0.554)
Ep: 118, Reward: 163.5862, Test: -43.1264 [16.95], Avg: -74.9325 (0.551)
Ep: 119, Reward: 201.0446, Test: -34.4641 [20.33], Avg: -74.7647 (0.548)
Ep: 120, Reward: 196.0438, Test: -39.7467 [19.08], Avg: -74.6330 (0.545)
Ep: 121, Reward: 203.3268, Test: -43.8967 [13.58], Avg: -74.4924 (0.543)
Ep: 122, Reward: 231.2917, Test: -43.8001 [21.34], Avg: -74.4163 (0.540)
Ep: 123, Reward: 242.6448, Test: -45.6213 [9.97], Avg: -74.2645 (0.537)
Ep: 124, Reward: 212.5949, Test: -40.4071 [17.17], Avg: -74.1310 (0.534)
Ep: 125, Reward: 260.8073, Test: -42.7253 [15.39], Avg: -74.0039 (0.532)
Ep: 126, Reward: 202.0882, Test: -30.9554 [10.28], Avg: -73.7458 (0.529)
Ep: 127, Reward: 195.2551, Test: -42.6254 [21.55], Avg: -73.6711 (0.526)
Ep: 128, Reward: 220.8321, Test: -57.4277 [9.79], Avg: -73.6210 (0.524)
Ep: 129, Reward: 199.4508, Test: -36.3022 [20.40], Avg: -73.4909 (0.521)
Ep: 130, Reward: 263.0692, Test: -43.0868 [16.46], Avg: -73.3845 (0.519)
Ep: 131, Reward: 205.5059, Test: -45.2443 [20.57], Avg: -73.3271 (0.516)
Ep: 132, Reward: 269.3912, Test: -36.6639 [16.15], Avg: -73.1729 (0.513)
Ep: 133, Reward: 263.5223, Test: -29.2989 [28.75], Avg: -73.0601 (0.511)
Ep: 134, Reward: 193.9318, Test: -38.7734 [18.21], Avg: -72.9410 (0.508)
Ep: 135, Reward: 232.6081, Test: -31.1628 [28.36], Avg: -72.8423 (0.506)
Ep: 136, Reward: 228.2168, Test: -27.0472 [20.43], Avg: -72.6572 (0.503)
Ep: 137, Reward: 257.3489, Test: -27.4850 [21.20], Avg: -72.4835 (0.501)
Ep: 138, Reward: 252.2862, Test: -25.8769 [29.23], Avg: -72.3585 (0.498)
Ep: 139, Reward: 233.0499, Test: -41.8394 [24.47], Avg: -72.3152 (0.496)
Ep: 140, Reward: 251.2822, Test: -29.6318 [18.92], Avg: -72.1467 (0.493)
Ep: 141, Reward: 283.8694, Test: -35.6936 [21.79], Avg: -72.0434 (0.491)
Ep: 142, Reward: 298.8008, Test: -39.2734 [15.12], Avg: -71.9200 (0.488)
Ep: 143, Reward: 345.4598, Test: -19.1065 [40.52], Avg: -71.8346 (0.486)
Ep: 144, Reward: 319.0165, Test: -20.7658 [38.05], Avg: -71.7448 (0.483)
Ep: 145, Reward: 222.0418, Test: -26.8734 [23.76], Avg: -71.6002 (0.481)
Ep: 146, Reward: 247.4037, Test: -36.7854 [25.75], Avg: -71.5385 (0.479)
Ep: 147, Reward: 227.4717, Test: -18.6664 [19.40], Avg: -71.3124 (0.476)
Ep: 148, Reward: 283.2826, Test: -28.9549 [24.46], Avg: -71.1922 (0.474)
Ep: 149, Reward: 401.8984, Test: -25.9711 [26.19], Avg: -71.0654 (0.471)
Ep: 150, Reward: 273.7647, Test: -18.5264 [18.03], Avg: -70.8368 (0.469)
Ep: 151, Reward: 337.1407, Test: -27.0789 [12.42], Avg: -70.6307 (0.467)
Ep: 152, Reward: 341.2316, Test: -14.3514 [29.50], Avg: -70.4557 (0.464)
Ep: 153, Reward: 299.3912, Test: -20.1686 [27.87], Avg: -70.3101 (0.462)
Ep: 154, Reward: 278.7038, Test: -13.0244 [31.28], Avg: -70.1423 (0.460)
Ep: 155, Reward: 339.9998, Test: -29.3478 [21.84], Avg: -70.0208 (0.458)
Ep: 156, Reward: 358.2302, Test: -32.5298 [15.75], Avg: -69.8824 (0.455)
Ep: 157, Reward: 352.3704, Test: -24.6035 [28.54], Avg: -69.7764 (0.453)
Ep: 158, Reward: 297.5217, Test: -16.8560 [49.40], Avg: -69.7543 (0.451)
Ep: 159, Reward: 298.0268, Test: -40.5204 [11.31], Avg: -69.6423 (0.448)
Ep: 160, Reward: 216.2666, Test: -34.0972 [23.20], Avg: -69.5656 (0.446)
Ep: 161, Reward: 224.3493, Test: -32.7610 [22.90], Avg: -69.4797 (0.444)
Ep: 162, Reward: 291.7104, Test: -27.7466 [18.44], Avg: -69.3369 (0.442)
Ep: 163, Reward: 269.9451, Test: -10.3954 [29.17], Avg: -69.1553 (0.440)
Ep: 164, Reward: 194.2484, Test: -26.2543 [22.17], Avg: -69.0297 (0.437)
Ep: 165, Reward: 225.0749, Test: -24.3068 [31.05], Avg: -68.9473 (0.435)
Ep: 166, Reward: 225.9330, Test: -29.2624 [25.37], Avg: -68.8616 (0.433)
Ep: 167, Reward: 318.9729, Test: -14.2333 [22.58], Avg: -68.6708 (0.431)
Ep: 168, Reward: 201.2798, Test: -36.9276 [16.35], Avg: -68.5797 (0.429)
Ep: 169, Reward: 283.1818, Test: -33.6229 [15.94], Avg: -68.4678 (0.427)
Ep: 170, Reward: 237.7184, Test: -27.2336 [21.80], Avg: -68.3542 (0.424)
Ep: 171, Reward: 252.3333, Test: -20.3244 [22.70], Avg: -68.2069 (0.422)
Ep: 172, Reward: 268.9996, Test: -29.4923 [21.28], Avg: -68.1061 (0.420)
Ep: 173, Reward: 282.6411, Test: -18.0594 [15.24], Avg: -67.9061 (0.418)
Ep: 174, Reward: 230.0072, Test: -28.0172 [22.75], Avg: -67.8082 (0.416)
Ep: 175, Reward: 206.1609, Test: -16.6701 [14.28], Avg: -67.5987 (0.414)
Ep: 176, Reward: 239.1903, Test: -26.3751 [28.96], Avg: -67.5295 (0.412)
Ep: 177, Reward: 270.3263, Test: -34.8134 [24.53], Avg: -67.4835 (0.410)
Ep: 178, Reward: 223.5054, Test: -24.3360 [20.80], Avg: -67.3586 (0.408)
Ep: 179, Reward: 293.4571, Test: -15.5653 [39.84], Avg: -67.2922 (0.406)
Ep: 180, Reward: 242.2309, Test: -28.6999 [26.82], Avg: -67.2272 (0.404)
Ep: 181, Reward: 227.9326, Test: -17.5824 [19.43], Avg: -67.0611 (0.402)
Ep: 182, Reward: 280.1409, Test: -35.2609 [16.65], Avg: -66.9783 (0.400)
Ep: 183, Reward: 270.9859, Test: -13.9205 [42.93], Avg: -66.9233 (0.398)
Ep: 184, Reward: 299.9798, Test: -24.8452 [21.49], Avg: -66.8120 (0.396)
Ep: 185, Reward: 222.0794, Test: -14.4647 [31.67], Avg: -66.7008 (0.394)
Ep: 186, Reward: 270.0681, Test: -20.6370 [22.28], Avg: -66.5736 (0.392)
Ep: 187, Reward: 254.3445, Test: -27.0910 [18.20], Avg: -66.4604 (0.390)
Ep: 188, Reward: 324.8581, Test: -33.0442 [29.74], Avg: -66.4410 (0.388)
Ep: 189, Reward: 344.1606, Test: -23.1093 [24.81], Avg: -66.3435 (0.386)
Ep: 190, Reward: 354.8581, Test: -22.3915 [22.24], Avg: -66.2299 (0.384)
Ep: 191, Reward: 220.1692, Test: -29.1313 [26.21], Avg: -66.1731 (0.382)
Ep: 192, Reward: 253.7843, Test: -21.3360 [16.59], Avg: -66.0268 (0.380)
Ep: 193, Reward: 174.5677, Test: -26.2753 [34.75], Avg: -66.0010 (0.378)
Ep: 194, Reward: 229.7455, Test: -22.0651 [16.12], Avg: -65.8584 (0.376)
Ep: 195, Reward: 218.2589, Test: -16.3063 [30.48], Avg: -65.7611 (0.374)
Ep: 196, Reward: 305.4429, Test: -19.0175 [37.94], Avg: -65.7164 (0.373)
Ep: 197, Reward: 331.0057, Test: -13.1215 [34.36], Avg: -65.6243 (0.371)
Ep: 198, Reward: 314.1908, Test: -39.0772 [18.90], Avg: -65.5858 (0.369)
Ep: 199, Reward: 278.7763, Test: -30.7244 [24.87], Avg: -65.5359 (0.367)
Ep: 200, Reward: 183.8752, Test: -32.7436 [20.71], Avg: -65.4757 (0.365)
Ep: 201, Reward: 249.6039, Test: -21.4144 [38.53], Avg: -65.4484 (0.363)
Ep: 202, Reward: 343.9523, Test: -27.6468 [21.17], Avg: -65.3665 (0.361)
Ep: 203, Reward: 224.8605, Test: -19.2153 [29.43], Avg: -65.2845 (0.360)
Ep: 204, Reward: 266.4811, Test: -25.1764 [23.18], Avg: -65.2019 (0.358)
Ep: 205, Reward: 323.7854, Test: -22.8198 [29.32], Avg: -65.1385 (0.356)
Ep: 206, Reward: 309.7798, Test: -10.6181 [49.88], Avg: -65.1160 (0.354)
Ep: 207, Reward: 286.7407, Test: -9.6988 [36.82], Avg: -65.0266 (0.353)
Ep: 208, Reward: 200.6739, Test: -9.8254 [49.15], Avg: -64.9977 (0.351)
Ep: 209, Reward: 217.2168, Test: -3.1981 [29.59], Avg: -64.8443 (0.349)
Ep: 210, Reward: 301.6916, Test: -12.5061 [54.28], Avg: -64.8535 (0.347)
Ep: 211, Reward: 311.9694, Test: -13.6227 [24.86], Avg: -64.7291 (0.346)
Ep: 212, Reward: 318.9593, Test: -12.8695 [44.43], Avg: -64.6942 (0.344)
Ep: 213, Reward: 286.8216, Test: -11.3288 [46.27], Avg: -64.6611 (0.342)
Ep: 214, Reward: 289.6629, Test: -9.1745 [33.27], Avg: -64.5577 (0.340)
Ep: 215, Reward: 286.6408, Test: -11.0931 [33.52], Avg: -64.4654 (0.339)
Ep: 216, Reward: 322.6423, Test: -16.4471 [22.18], Avg: -64.3463 (0.337)
Ep: 217, Reward: 249.7759, Test: -18.8750 [21.18], Avg: -64.2349 (0.335)
Ep: 218, Reward: 288.3156, Test: -2.6361 [34.01], Avg: -64.1089 (0.334)
Ep: 219, Reward: 238.6083, Test: -21.0090 [14.97], Avg: -63.9810 (0.332)
Ep: 220, Reward: 264.3696, Test: -8.9496 [36.84], Avg: -63.8987 (0.330)
Ep: 221, Reward: 288.3622, Test: -21.9676 [23.97], Avg: -63.8178 (0.329)
Ep: 222, Reward: 364.4294, Test: -22.5544 [17.02], Avg: -63.7091 (0.327)
Ep: 223, Reward: 315.5527, Test: -11.7983 [34.50], Avg: -63.6313 (0.325)
Ep: 224, Reward: 302.0459, Test: -14.8540 [33.85], Avg: -63.5650 (0.324)
Ep: 225, Reward: 364.7367, Test: 2.1907 [55.85], Avg: -63.5212 (0.322)
Ep: 226, Reward: 387.0020, Test: 2.3077 [49.28], Avg: -63.4483 (0.321)
Ep: 227, Reward: 365.5206, Test: -23.7266 [23.22], Avg: -63.3759 (0.319)
Ep: 228, Reward: 336.6513, Test: -20.9720 [24.85], Avg: -63.2993 (0.317)
Ep: 229, Reward: 351.6226, Test: -3.2435 [25.39], Avg: -63.1485 (0.316)
Ep: 230, Reward: 275.3986, Test: -24.2249 [17.66], Avg: -63.0564 (0.314)
Ep: 231, Reward: 351.7232, Test: -17.1117 [27.18], Avg: -62.9756 (0.313)
Ep: 232, Reward: 350.4624, Test: -31.4908 [13.71], Avg: -62.8993 (0.311)
Ep: 233, Reward: 347.9737, Test: 8.7460 [31.27], Avg: -62.7267 (0.309)
Ep: 234, Reward: 372.0432, Test: -17.4906 [29.99], Avg: -62.6618 (0.308)
Ep: 235, Reward: 306.7855, Test: -12.8746 [22.84], Avg: -62.5476 (0.306)
Ep: 236, Reward: 386.6564, Test: -24.0613 [33.21], Avg: -62.5254 (0.305)
Ep: 237, Reward: 272.6847, Test: -6.8041 [25.90], Avg: -62.4001 (0.303)
Ep: 238, Reward: 278.2681, Test: -9.9727 [30.81], Avg: -62.3096 (0.302)
Ep: 239, Reward: 319.6278, Test: -11.6647 [34.18], Avg: -62.2410 (0.300)
Ep: 240, Reward: 256.4989, Test: -21.8776 [16.89], Avg: -62.1436 (0.299)
Ep: 241, Reward: 261.0413, Test: -28.1519 [19.71], Avg: -62.0846 (0.297)
Ep: 242, Reward: 371.1650, Test: -11.3560 [38.78], Avg: -62.0354 (0.296)
Ep: 243, Reward: 332.6550, Test: -21.6344 [19.24], Avg: -61.9487 (0.294)
Ep: 244, Reward: 362.1582, Test: -24.7476 [26.28], Avg: -61.9041 (0.293)
Ep: 245, Reward: 346.8280, Test: -27.3561 [30.59], Avg: -61.8881 (0.291)
Ep: 246, Reward: 325.4290, Test: -23.2825 [27.28], Avg: -61.8422 (0.290)
Ep: 247, Reward: 253.4018, Test: 2.1998 [27.77], Avg: -61.6959 (0.288)
Ep: 248, Reward: 292.4718, Test: -21.5358 [24.91], Avg: -61.6347 (0.287)
Ep: 249, Reward: 324.8484, Test: -0.1449 [33.38], Avg: -61.5222 (0.286)
Ep: 250, Reward: 359.8888, Test: -14.8396 [17.47], Avg: -61.4059 (0.284)
Ep: 251, Reward: 334.2800, Test: -20.6752 [28.64], Avg: -61.3579 (0.283)
Ep: 252, Reward: 299.8441, Test: -20.5661 [25.99], Avg: -61.2993 (0.281)
Ep: 253, Reward: 410.1843, Test: -11.4515 [44.17], Avg: -61.2770 (0.280)
Ep: 254, Reward: 414.1190, Test: -24.8984 [21.27], Avg: -61.2177 (0.279)
Ep: 255, Reward: 365.6792, Test: -26.8159 [24.07], Avg: -61.1774 (0.277)
Ep: 256, Reward: 428.8964, Test: -35.1238 [24.63], Avg: -61.1718 (0.276)
Ep: 257, Reward: 410.4611, Test: 6.6831 [31.00], Avg: -61.0290 (0.274)
Ep: 258, Reward: 416.0132, Test: -10.4187 [30.83], Avg: -60.9526 (0.273)
Ep: 259, Reward: 393.1956, Test: -18.4513 [18.88], Avg: -60.8618 (0.272)
Ep: 260, Reward: 385.3624, Test: -7.1907 [51.21], Avg: -60.8523 (0.270)
Ep: 261, Reward: 397.0241, Test: 9.5883 [33.79], Avg: -60.7124 (0.269)
Ep: 262, Reward: 445.3976, Test: -8.7137 [32.16], Avg: -60.6370 (0.268)
Ep: 263, Reward: 392.7301, Test: 5.0440 [46.25], Avg: -60.5634 (0.266)
Ep: 264, Reward: 460.5522, Test: 4.2093 [23.51], Avg: -60.4077 (0.265)
Ep: 265, Reward: 402.4548, Test: -7.9462 [36.97], Avg: -60.3495 (0.264)
Ep: 266, Reward: 379.2930, Test: -10.8528 [37.67], Avg: -60.3052 (0.262)
Ep: 267, Reward: 425.8513, Test: -29.0138 [32.51], Avg: -60.3097 (0.261)
Ep: 268, Reward: 360.0837, Test: -19.9365 [15.17], Avg: -60.2160 (0.260)
Ep: 269, Reward: 407.5418, Test: 0.9045 [33.84], Avg: -60.1150 (0.258)
Ep: 270, Reward: 431.1943, Test: 22.9440 [58.82], Avg: -60.0255 (0.257)
Ep: 271, Reward: 409.5832, Test: -6.2940 [33.55], Avg: -59.9514 (0.256)
Ep: 272, Reward: 526.9024, Test: -3.4634 [32.37], Avg: -59.8630 (0.255)
Ep: 273, Reward: 519.7307, Test: 3.3045 [62.46], Avg: -59.8604 (0.253)
Ep: 274, Reward: 482.9946, Test: -12.9466 [16.93], Avg: -59.7514 (0.252)
Ep: 275, Reward: 393.6092, Test: 0.0758 [42.41], Avg: -59.6883 (0.251)
Ep: 276, Reward: 440.3727, Test: 10.7494 [31.80], Avg: -59.5489 (0.249)
Ep: 277, Reward: 480.0829, Test: -3.3521 [51.56], Avg: -59.5322 (0.248)
Ep: 278, Reward: 430.4541, Test: -0.1505 [42.86], Avg: -59.4730 (0.247)
Ep: 279, Reward: 495.6835, Test: 8.8421 [45.17], Avg: -59.3903 (0.246)
Ep: 280, Reward: 489.0131, Test: 18.9027 [55.37], Avg: -59.3087 (0.245)
Ep: 281, Reward: 433.2552, Test: -3.4079 [34.30], Avg: -59.2321 (0.243)
Ep: 282, Reward: 479.3331, Test: -4.7924 [40.22], Avg: -59.1818 (0.242)
Ep: 283, Reward: 452.1441, Test: 17.0973 [59.30], Avg: -59.1221 (0.241)
Ep: 284, Reward: 503.7771, Test: 12.4844 [33.62], Avg: -58.9888 (0.240)
Ep: 285, Reward: 559.0583, Test: -9.1560 [41.60], Avg: -58.9600 (0.238)
Ep: 286, Reward: 495.2463, Test: 12.2338 [55.87], Avg: -58.9066 (0.237)
Ep: 287, Reward: 607.0731, Test: 10.5257 [45.24], Avg: -58.8226 (0.236)
Ep: 288, Reward: 451.9070, Test: 6.3433 [69.68], Avg: -58.8382 (0.235)
Ep: 289, Reward: 438.9865, Test: -2.6636 [40.31], Avg: -58.7835 (0.234)
Ep: 290, Reward: 605.3192, Test: 13.1160 [44.17], Avg: -58.6882 (0.233)
Ep: 291, Reward: 440.8275, Test: -11.6390 [36.75], Avg: -58.6529 (0.231)
Ep: 292, Reward: 473.4552, Test: -5.7630 [22.90], Avg: -58.5506 (0.230)
Ep: 293, Reward: 490.0229, Test: -23.1012 [16.74], Avg: -58.4869 (0.229)
Ep: 294, Reward: 600.8392, Test: 26.5876 [79.30], Avg: -58.4674 (0.228)
Ep: 295, Reward: 458.5229, Test: 19.7596 [50.77], Avg: -58.3746 (0.227)
Ep: 296, Reward: 427.7753, Test: 17.4246 [69.51], Avg: -58.3534 (0.226)
Ep: 297, Reward: 451.8579, Test: -7.2093 [37.18], Avg: -58.3066 (0.225)
Ep: 298, Reward: 468.6361, Test: -4.6132 [43.28], Avg: -58.2717 (0.223)
Ep: 299, Reward: 548.1755, Test: 0.8920 [25.69], Avg: -58.1601 (0.222)
Ep: 300, Reward: 370.5214, Test: 26.3874 [71.29], Avg: -58.1161 (0.221)
Ep: 301, Reward: 492.8505, Test: -21.3110 [25.33], Avg: -58.0781 (0.220)
Ep: 302, Reward: 370.5719, Test: 12.8542 [55.08], Avg: -58.0258 (0.219)
Ep: 303, Reward: 391.3270, Test: 9.3827 [26.63], Avg: -57.8916 (0.218)
Ep: 304, Reward: 418.5265, Test: 25.4422 [64.42], Avg: -57.8296 (0.217)
Ep: 305, Reward: 486.0470, Test: 11.5645 [31.63], Avg: -57.7062 (0.216)
Ep: 306, Reward: 512.1189, Test: -2.5007 [24.28], Avg: -57.6055 (0.215)
Ep: 307, Reward: 419.2160, Test: 10.6654 [52.84], Avg: -57.5554 (0.214)
Ep: 308, Reward: 489.4354, Test: -5.5621 [34.91], Avg: -57.5001 (0.212)
Ep: 309, Reward: 452.8773, Test: 42.6475 [71.35], Avg: -57.4072 (0.211)
Ep: 310, Reward: 489.0241, Test: 14.1907 [46.52], Avg: -57.3265 (0.210)
Ep: 311, Reward: 567.4533, Test: 1.6434 [29.65], Avg: -57.2326 (0.209)
Ep: 312, Reward: 484.1831, Test: 8.7404 [40.28], Avg: -57.1505 (0.208)
Ep: 313, Reward: 565.7436, Test: 12.0549 [48.93], Avg: -57.0859 (0.207)
Ep: 314, Reward: 521.6237, Test: 8.1158 [27.50], Avg: -56.9662 (0.206)
Ep: 315, Reward: 465.0813, Test: 3.2737 [32.95], Avg: -56.8798 (0.205)
Ep: 316, Reward: 520.9852, Test: 2.9508 [51.15], Avg: -56.8524 (0.204)
Ep: 317, Reward: 544.3313, Test: 6.9725 [43.06], Avg: -56.7871 (0.203)
Ep: 318, Reward: 510.5271, Test: -2.4956 [15.75], Avg: -56.6663 (0.202)
Ep: 319, Reward: 445.1015, Test: 13.6188 [37.44], Avg: -56.5637 (0.201)
Ep: 320, Reward: 560.8055, Test: 7.6867 [40.79], Avg: -56.4906 (0.200)
Ep: 321, Reward: 488.8793, Test: -3.8484 [22.54], Avg: -56.3971 (0.199)
Ep: 322, Reward: 443.2997, Test: 50.0927 [77.43], Avg: -56.3072 (0.198)
Ep: 323, Reward: 537.1312, Test: 6.1986 [31.44], Avg: -56.2113 (0.197)
Ep: 324, Reward: 528.0551, Test: 13.3847 [34.37], Avg: -56.1029 (0.196)
Ep: 325, Reward: 533.2140, Test: -9.7444 [45.47], Avg: -56.1002 (0.195)
Ep: 326, Reward: 567.4213, Test: -0.1688 [47.65], Avg: -56.0748 (0.194)
Ep: 327, Reward: 617.4231, Test: 1.6468 [24.54], Avg: -55.9737 (0.193)
Ep: 328, Reward: 524.5720, Test: 18.3026 [35.22], Avg: -55.8550 (0.192)
Ep: 329, Reward: 513.0800, Test: 25.2968 [57.61], Avg: -55.7837 (0.191)
Ep: 330, Reward: 585.2787, Test: -15.5007 [21.70], Avg: -55.7275 (0.190)
Ep: 331, Reward: 526.7588, Test: 30.3167 [44.88], Avg: -55.6035 (0.189)
Ep: 332, Reward: 576.7720, Test: 10.2561 [44.40], Avg: -55.5391 (0.188)
Ep: 333, Reward: 491.5229, Test: 40.9412 [44.30], Avg: -55.3829 (0.187)
Ep: 334, Reward: 578.7306, Test: -9.3048 [34.42], Avg: -55.3481 (0.187)
Ep: 335, Reward: 600.8814, Test: -10.2577 [27.94], Avg: -55.2970 (0.186)
Ep: 336, Reward: 428.5845, Test: -1.7855 [31.55], Avg: -55.2318 (0.185)
Ep: 337, Reward: 436.8914, Test: 32.1374 [66.74], Avg: -55.1708 (0.184)
Ep: 338, Reward: 527.2917, Test: 27.0150 [86.74], Avg: -55.1842 (0.183)
Ep: 339, Reward: 514.2025, Test: 24.7800 [65.47], Avg: -55.1416 (0.182)
Ep: 340, Reward: 528.0823, Test: -2.6050 [24.69], Avg: -55.0599 (0.181)
Ep: 341, Reward: 422.6204, Test: 17.9528 [35.41], Avg: -54.9500 (0.180)
Ep: 342, Reward: 416.4222, Test: -9.7095 [11.51], Avg: -54.8517 (0.179)
Ep: 343, Reward: 397.0097, Test: 12.5944 [40.49], Avg: -54.7733 (0.178)
Ep: 344, Reward: 453.6478, Test: -7.5095 [28.02], Avg: -54.7175 (0.177)
Ep: 345, Reward: 434.2327, Test: 7.0067 [33.85], Avg: -54.6370 (0.177)
Ep: 346, Reward: 529.0252, Test: 18.9793 [37.61], Avg: -54.5332 (0.176)
Ep: 347, Reward: 557.2261, Test: 19.4581 [49.82], Avg: -54.4637 (0.175)
Ep: 348, Reward: 617.4277, Test: 2.5335 [35.96], Avg: -54.4035 (0.174)
Ep: 349, Reward: 562.5731, Test: 2.7531 [37.08], Avg: -54.3461 (0.173)
Ep: 350, Reward: 544.8876, Test: 45.3759 [54.38], Avg: -54.2169 (0.172)
Ep: 351, Reward: 562.8489, Test: 11.9756 [30.14], Avg: -54.1145 (0.171)
Ep: 352, Reward: 635.1626, Test: 21.0484 [52.87], Avg: -54.0514 (0.170)
Ep: 353, Reward: 499.1659, Test: 45.1220 [99.20], Avg: -54.0514 (0.170)
Ep: 354, Reward: 557.4748, Test: 8.2489 [45.31], Avg: -54.0036 (0.169)
Ep: 355, Reward: 543.4180, Test: 24.7485 [37.56], Avg: -53.8879 (0.168)
Ep: 356, Reward: 495.9595, Test: 32.5012 [67.08], Avg: -53.8338 (0.167)
Ep: 357, Reward: 546.1489, Test: 10.0085 [35.89], Avg: -53.7557 (0.166)
Ep: 358, Reward: 535.1130, Test: 41.5895 [44.53], Avg: -53.6141 (0.165)
Ep: 359, Reward: 562.4078, Test: 37.2332 [57.42], Avg: -53.5213 (0.165)
Ep: 360, Reward: 405.4553, Test: 13.2227 [60.82], Avg: -53.5049 (0.164)
Ep: 361, Reward: 483.0876, Test: 39.8005 [80.85], Avg: -53.4705 (0.163)
Ep: 362, Reward: 577.5729, Test: 8.2699 [31.36], Avg: -53.3868 (0.162)
Ep: 363, Reward: 500.4068, Test: 12.6406 [44.72], Avg: -53.3283 (0.161)
Ep: 364, Reward: 496.8746, Test: 52.3069 [77.72], Avg: -53.2518 (0.160)
Ep: 365, Reward: 569.3560, Test: 12.2697 [56.78], Avg: -53.2279 (0.160)
Ep: 366, Reward: 500.8083, Test: -4.3838 [30.10], Avg: -53.1768 (0.159)
Ep: 367, Reward: 456.1458, Test: 14.9410 [75.95], Avg: -53.1981 (0.158)
Ep: 368, Reward: 584.8171, Test: 15.6434 [46.02], Avg: -53.1362 (0.157)
Ep: 369, Reward: 503.0216, Test: 35.0423 [83.29], Avg: -53.1230 (0.157)
Ep: 370, Reward: 457.8358, Test: 2.4631 [46.18], Avg: -53.0977 (0.156)
Ep: 371, Reward: 566.0708, Test: 4.7033 [55.99], Avg: -53.0928 (0.155)
Ep: 372, Reward: 598.6382, Test: 26.0799 [70.63], Avg: -53.0699 (0.154)
Ep: 373, Reward: 499.6310, Test: 19.8762 [40.71], Avg: -52.9837 (0.153)
Ep: 374, Reward: 488.3886, Test: 1.7600 [39.29], Avg: -52.9425 (0.153)
Ep: 375, Reward: 554.9950, Test: -6.8524 [39.90], Avg: -52.9261 (0.152)
Ep: 376, Reward: 548.1461, Test: 3.7298 [29.56], Avg: -52.8542 (0.151)
Ep: 377, Reward: 556.0295, Test: 4.8041 [25.71], Avg: -52.7697 (0.150)
Ep: 378, Reward: 580.2391, Test: -28.8436 [27.83], Avg: -52.7800 (0.150)
Ep: 379, Reward: 503.3567, Test: 2.5954 [23.63], Avg: -52.6964 (0.149)
Ep: 380, Reward: 567.7672, Test: -8.6020 [34.69], Avg: -52.6717 (0.148)
Ep: 381, Reward: 534.9713, Test: 22.7875 [33.18], Avg: -52.5611 (0.147)
Ep: 382, Reward: 480.1683, Test: -4.5597 [44.51], Avg: -52.5520 (0.147)
Ep: 383, Reward: 557.4632, Test: -2.0376 [28.91], Avg: -52.4957 (0.146)
Ep: 384, Reward: 523.5853, Test: -7.2452 [28.82], Avg: -52.4530 (0.145)
Ep: 385, Reward: 488.7239, Test: -11.8412 [37.59], Avg: -52.4452 (0.144)
Ep: 386, Reward: 449.9595, Test: -4.6431 [33.52], Avg: -52.4083 (0.144)
Ep: 387, Reward: 509.2246, Test: 19.7669 [67.32], Avg: -52.3958 (0.143)
Ep: 388, Reward: 529.0853, Test: 14.4296 [46.36], Avg: -52.3431 (0.142)
Ep: 389, Reward: 513.6735, Test: 16.4269 [75.97], Avg: -52.3616 (0.142)
Ep: 390, Reward: 499.8603, Test: -10.3636 [25.87], Avg: -52.3203 (0.141)
Ep: 391, Reward: 477.7324, Test: 28.6645 [98.39], Avg: -52.3647 (0.140)
Ep: 392, Reward: 495.1406, Test: 22.8382 [83.17], Avg: -52.3850 (0.139)
Ep: 393, Reward: 471.8192, Test: 18.8885 [57.74], Avg: -52.3506 (0.139)
Ep: 394, Reward: 405.5267, Test: 10.9884 [53.03], Avg: -52.3245 (0.138)
Ep: 395, Reward: 522.5548, Test: 0.5969 [51.35], Avg: -52.3206 (0.137)
Ep: 396, Reward: 543.0330, Test: 8.6026 [49.49], Avg: -52.2918 (0.137)
Ep: 397, Reward: 491.0762, Test: -4.4817 [35.92], Avg: -52.2619 (0.136)
Ep: 398, Reward: 404.8754, Test: -8.0376 [34.07], Avg: -52.2364 (0.135)
Ep: 399, Reward: 520.0902, Test: -7.2900 [34.67], Avg: -52.2107 (0.135)
Ep: 400, Reward: 419.2926, Test: -7.8605 [22.25], Avg: -52.1556 (0.134)
Ep: 401, Reward: 507.8588, Test: 9.0652 [38.23], Avg: -52.0984 (0.133)
Ep: 402, Reward: 535.3873, Test: -2.8458 [36.33], Avg: -52.0664 (0.133)
Ep: 403, Reward: 468.3664, Test: 16.7668 [65.85], Avg: -52.0590 (0.132)
Ep: 404, Reward: 495.4043, Test: 12.6784 [39.51], Avg: -51.9967 (0.131)
Ep: 405, Reward: 461.8756, Test: 0.9449 [38.96], Avg: -51.9622 (0.131)
Ep: 406, Reward: 408.9837, Test: 15.9161 [86.65], Avg: -52.0083 (0.130)
Ep: 407, Reward: 445.6370, Test: 1.5384 [44.95], Avg: -51.9873 (0.129)
Ep: 408, Reward: 545.9183, Test: 0.0458 [32.33], Avg: -51.9391 (0.129)
Ep: 409, Reward: 551.9049, Test: -7.5391 [37.78], Avg: -51.9229 (0.128)
Ep: 410, Reward: 542.3335, Test: 15.1898 [70.55], Avg: -51.9313 (0.127)
Ep: 411, Reward: 483.6631, Test: -4.2951 [36.79], Avg: -51.9050 (0.127)
Ep: 412, Reward: 564.8616, Test: -10.6908 [41.66], Avg: -51.9061 (0.126)
Ep: 413, Reward: 649.8705, Test: -2.6951 [51.41], Avg: -51.9114 (0.126)
Ep: 414, Reward: 470.9874, Test: -6.5172 [45.77], Avg: -51.9123 (0.125)
Ep: 415, Reward: 604.6473, Test: -12.5518 [16.06], Avg: -51.8563 (0.124)
Ep: 416, Reward: 572.4906, Test: 12.9015 [99.96], Avg: -51.9407 (0.124)
Ep: 417, Reward: 551.4461, Test: -5.0224 [40.39], Avg: -51.9251 (0.123)
Ep: 418, Reward: 504.3336, Test: -20.1411 [36.56], Avg: -51.9365 (0.122)
Ep: 419, Reward: 447.4252, Test: -11.1180 [17.69], Avg: -51.8814 (0.122)
Ep: 420, Reward: 506.9279, Test: -29.7291 [42.70], Avg: -51.9302 (0.121)
Ep: 421, Reward: 560.0572, Test: 16.2720 [42.75], Avg: -51.8699 (0.121)
Ep: 422, Reward: 531.5446, Test: -4.2285 [62.61], Avg: -51.9053 (0.120)
Ep: 423, Reward: 505.7012, Test: 1.2639 [38.99], Avg: -51.8719 (0.119)
Ep: 424, Reward: 542.1327, Test: 14.0909 [67.56], Avg: -51.8756 (0.119)
Ep: 425, Reward: 507.0159, Test: 33.1421 [85.68], Avg: -51.8772 (0.118)
Ep: 426, Reward: 518.2203, Test: 1.1454 [36.90], Avg: -51.8395 (0.118)
Ep: 427, Reward: 576.5046, Test: 7.6023 [34.76], Avg: -51.7818 (0.117)
Ep: 428, Reward: 546.6441, Test: 36.4799 [95.66], Avg: -51.7990 (0.116)
Ep: 429, Reward: 536.9425, Test: 30.8797 [55.62], Avg: -51.7361 (0.116)
Ep: 430, Reward: 531.3663, Test: 15.1627 [64.64], Avg: -51.7308 (0.115)
Ep: 431, Reward: 516.7408, Test: -7.2856 [35.47], Avg: -51.7101 (0.115)
Ep: 432, Reward: 476.4131, Test: -21.6637 [34.88], Avg: -51.7212 (0.114)
Ep: 433, Reward: 515.0427, Test: 5.5115 [57.64], Avg: -51.7222 (0.114)
Ep: 434, Reward: 499.8670, Test: -17.7044 [35.79], Avg: -51.7262 (0.113)
Ep: 435, Reward: 520.3094, Test: -5.8101 [37.53], Avg: -51.7070 (0.112)
Ep: 436, Reward: 518.0401, Test: 0.3318 [53.00], Avg: -51.7092 (0.112)
Ep: 437, Reward: 507.6158, Test: 25.4591 [58.51], Avg: -51.6666 (0.111)
Ep: 438, Reward: 622.8201, Test: -4.3076 [51.73], Avg: -51.6766 (0.111)
Ep: 439, Reward: 614.4273, Test: -10.0010 [43.93], Avg: -51.6817 (0.110)
Ep: 440, Reward: 569.3052, Test: 69.9703 [99.80], Avg: -51.6321 (0.110)
Ep: 441, Reward: 589.5132, Test: 41.9207 [92.23], Avg: -51.6291 (0.109)
Ep: 442, Reward: 465.9573, Test: 2.0776 [66.47], Avg: -51.6579 (0.109)
Ep: 443, Reward: 577.2848, Test: 15.4568 [49.21], Avg: -51.6176 (0.108)
Ep: 444, Reward: 450.1332, Test: -1.1334 [59.54], Avg: -51.6380 (0.107)
Ep: 445, Reward: 480.3200, Test: 26.3053 [72.37], Avg: -51.6255 (0.107)
Ep: 446, Reward: 493.4821, Test: 39.5569 [107.92], Avg: -51.6629 (0.106)
Ep: 447, Reward: 512.0995, Test: 60.8559 [102.56], Avg: -51.6407 (0.106)
Ep: 448, Reward: 621.3316, Test: 20.6548 [62.14], Avg: -51.6181 (0.105)
Ep: 449, Reward: 476.0601, Test: 17.6959 [64.40], Avg: -51.6071 (0.105)
Ep: 450, Reward: 649.4661, Test: -0.4955 [43.40], Avg: -51.5900 (0.104)
Ep: 451, Reward: 549.2822, Test: 28.7040 [85.85], Avg: -51.6023 (0.104)
Ep: 452, Reward: 534.8330, Test: 11.0270 [79.26], Avg: -51.6390 (0.103)
Ep: 453, Reward: 596.6315, Test: 31.7921 [86.28], Avg: -51.6453 (0.103)
Ep: 454, Reward: 439.3092, Test: -13.6284 [17.13], Avg: -51.5994 (0.102)
Ep: 455, Reward: 537.0708, Test: 6.9843 [39.27], Avg: -51.5571 (0.102)
Ep: 456, Reward: 491.4852, Test: 1.9362 [50.76], Avg: -51.5511 (0.101)
Ep: 457, Reward: 474.2366, Test: 5.2577 [42.49], Avg: -51.5198 (0.101)
Ep: 458, Reward: 559.9329, Test: -2.9977 [36.23], Avg: -51.4930 (0.100)
Ep: 459, Reward: 558.0010, Test: 16.2133 [79.00], Avg: -51.5176 (0.100)
Ep: 460, Reward: 660.5295, Test: 19.4195 [56.67], Avg: -51.4866 (0.100)
Ep: 461, Reward: 514.3718, Test: -8.8561 [27.40], Avg: -51.4537 (0.100)
Ep: 462, Reward: 493.2621, Test: 19.9559 [87.45], Avg: -51.4883 (0.100)
Ep: 463, Reward: 430.9496, Test: -8.0016 [32.84], Avg: -51.4653 (0.100)
Ep: 464, Reward: 606.0402, Test: -3.7042 [64.67], Avg: -51.5017 (0.100)
Ep: 465, Reward: 479.0430, Test: 33.6869 [69.07], Avg: -51.4671 (0.100)
Ep: 466, Reward: 527.3138, Test: -9.3440 [28.20], Avg: -51.4373 (0.100)
Ep: 467, Reward: 538.5698, Test: -16.4182 [22.38], Avg: -51.4103 (0.100)
Ep: 468, Reward: 583.3706, Test: -19.3433 [31.93], Avg: -51.4100 (0.100)
Ep: 469, Reward: 514.8233, Test: 32.5485 [67.53], Avg: -51.3750 (0.100)
Ep: 470, Reward: 557.4628, Test: 28.4380 [79.03], Avg: -51.3734 (0.100)
Ep: 471, Reward: 643.7083, Test: -17.0708 [39.65], Avg: -51.3847 (0.100)
Ep: 472, Reward: 576.6201, Test: 33.6123 [35.45], Avg: -51.2800 (0.100)
Ep: 473, Reward: 516.5709, Test: 0.6965 [91.84], Avg: -51.3641 (0.100)
Ep: 474, Reward: 504.8213, Test: -2.2378 [70.99], Avg: -51.4101 (0.100)
Ep: 475, Reward: 586.9932, Test: 10.7785 [48.88], Avg: -51.3821 (0.100)
Ep: 476, Reward: 520.3312, Test: -18.2664 [32.47], Avg: -51.3808 (0.100)
Ep: 477, Reward: 544.3564, Test: 18.0339 [73.76], Avg: -51.3899 (0.100)
Ep: 478, Reward: 427.4509, Test: 23.1250 [66.36], Avg: -51.3728 (0.100)
Ep: 479, Reward: 567.1810, Test: 9.0908 [56.82], Avg: -51.3653 (0.100)
Ep: 480, Reward: 549.1470, Test: 39.2806 [86.47], Avg: -51.3566 (0.100)
Ep: 481, Reward: 572.5773, Test: 25.6733 [77.30], Avg: -51.3571 (0.100)
Ep: 482, Reward: 627.2095, Test: 51.1854 [82.02], Avg: -51.3146 (0.100)
Ep: 483, Reward: 481.3292, Test: -4.7990 [37.43], Avg: -51.2959 (0.100)
Ep: 484, Reward: 469.2385, Test: 20.4907 [55.77], Avg: -51.2628 (0.100)
Ep: 485, Reward: 489.9960, Test: 32.7408 [78.75], Avg: -51.2520 (0.100)
Ep: 486, Reward: 487.6423, Test: -0.9367 [46.52], Avg: -51.2442 (0.100)
Ep: 487, Reward: 587.1063, Test: 27.9381 [78.90], Avg: -51.2436 (0.100)
Ep: 488, Reward: 558.3355, Test: 38.0475 [99.15], Avg: -51.2638 (0.100)
Ep: 489, Reward: 553.1438, Test: 50.2587 [137.24], Avg: -51.3367 (0.100)
Ep: 490, Reward: 478.8349, Test: 41.8247 [86.64], Avg: -51.3234 (0.100)
Ep: 491, Reward: 534.2964, Test: 23.7593 [66.53], Avg: -51.3060 (0.100)
Ep: 492, Reward: 650.5345, Test: 15.7780 [44.76], Avg: -51.2608 (0.100)
Ep: 493, Reward: 460.9649, Test: 15.1553 [49.73], Avg: -51.2270 (0.100)
Ep: 494, Reward: 505.3082, Test: 20.2926 [34.55], Avg: -51.1523 (0.100)
Ep: 495, Reward: 530.0895, Test: -20.2528 [21.96], Avg: -51.1343 (0.100)
